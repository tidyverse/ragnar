[{"path":"https://ragnar.tidyverse.org/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 ragnar authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"getting-started-with-ragnar","dir":"Articles","previous_headings":"","what":"Getting Started with ragnar","title":"ragnar","text":"Retrieval-Augmented Generation (RAG) practical technique improving large language model (LLM) outputs grounding external, trusted content. ragnar package provides tools building RAG workflows R, focus transparency control step. guide walks building simple chat tool Quarto documentation using ragnar. code examples simplified clarity; full implementation, see https://github.com/t-kalinowski/quartohelp.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"why-rag-the-hallucination-problem","dir":"Articles","previous_headings":"Getting Started with ragnar","what":"Why RAG? The Hallucination Problem","title":"ragnar","text":"LLMs can produce remarkable outputs: fluent, confident, plausible responses wide range prompts. anyone spent time ChatGPT similar models observed responses confident, plausible, wrong. generated output wrong, call hallucination, hallucinations seem inherent consequence LLMs work. LLMs operate text sequences; seem possess concept “facts” “truth” like humans . generate text awareness whether true false, guided similarity patterns text sequences training data. Put simply, philosopher Harry Frankfurt’s sense word, models generate “bullshit” 1: impossible someone lie unless thinks knows truth. Producing bullshit requires conviction. person lies thereby responding truth, extent respectful . honest man speaks, says believes true; liar, correspondingly indispensable considers statements false. bullshitter, however, bets : neither side true side false. eye facts , eyes honest man liar , except insofar may pertinent interest getting away says. care whether things says describe reality correctly. just picks , makes , suit purpose. RAG addresses retrieving relevant excerpts corpus trusted, vetted sources asking LLM summarize, paraphrase, answer user’s question using material. grounds response known content reduces risk hallucination. RAG shifts LLM’s job open-ended generation summarizing quoting retrieved material. RAG reduces eliminate hallucinations. richer texts tasks, LLMs may still miss nuance overgeneralize. reason, ’s helpful RAG-based tools present links back original material users can check context verify details.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"use-case-quarto-docs-chat-vs--standard-search","dir":"Articles","previous_headings":"Getting Started with ragnar","what":"Use Case: Quarto Docs Chat vs. Standard Search","title":"ragnar","text":"Standard documentation search default answering questions tools like Quarto limitations. Search requires precise wording, familiarity docs’ structure, sometimes piecing together information multiple pages. Even focused site search, users spend time skimming navigating correct material, may still miss answer. RAG-powered chat tool offer better alternative. ask natural language question. tool retrieves relevant excerpts docs using semantic keyword-based search, asks LLM answer using excerpts. result concise, context-aware answer, complete links relevant docs. course, useful LLM actually provides correct useful answers.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"setting-up-rag","dir":"Articles","previous_headings":"Getting Started with ragnar","what":"Setting up RAG","title":"ragnar","text":"high level, setting RAG two stages: preparing knowledge store (database processed content), establishing workflow retrieval chat.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"creating-the-store","dir":"Articles","previous_headings":"Getting Started with ragnar > Setting up RAG","what":"Creating the Store","title":"ragnar","text":"First, create store. store holds processed docs embeddings. create store, select embedding provider. choice fixed store, can always create new store want change . generate embeddings, can use open-source model via embed_ollama(), models commercial providers via embed_openai(), embed_google_vertex(), embed_bedrock(), embed_databricks(), function.","code":"store_location <- \"quarto.ragnar.duckdb\" store <- ragnar_store_create(   store_location,   embed = \\(x) ragnar::embed_openai(x, model = \"text-embedding-3-small\") )"},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"identify-documents-for-processing","dir":"Articles","previous_headings":"Getting Started with ragnar > Setting up RAG","what":"Identify Documents for Processing","title":"ragnar","text":"Gather list documents want insert database. local files, can simple list.files() directory documents. ’re building store website, can use ragnar_find_links() collect URLs. sites, may easier clone build site locally, reference files local file system. can also process sitemap one available. end step, character vector file paths URLs.","code":"paths <- ragnar_find_links(\"https://quarto.org/\", depth = 3)"},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"convert-documents-to-markdown","dir":"Articles","previous_headings":"Getting Started with ragnar > Setting up RAG","what":"Convert Documents to Markdown","title":"ragnar","text":"Convert document markdown. Markdown preferred ’s plain text, easy inspect, keeps token counts low, works well humans LLMs. step, ragnar provides read_as_markdown(), can accept wide variety formats (pdf, docx, pptx, html, zip files, epubs, etc.). many cases works well, specialized needs can opt custom-tailored approach. See help ?read_as_markdown guidance alternatives ’d like improve default conversion. (begin optimizing basic app working.) read_as_markdown() returns MarkdownDocument object, normalized string markdown text @origin property. opt use something besides read_as_markdown() read content–readLines(), pdftools::pdf_text(), sophisticated OCR tool–can turn character vector ragnar::MarkdownDocument object MarkdownDocument() constructor.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"chunk-and-augment","dir":"Articles","previous_headings":"Getting Started with ragnar > Setting up RAG","what":"Chunk and Augment","title":"ragnar","text":"Next, split documents smaller chunks. necessary embedding models context size limits, chunking allows return just relevant excerpts long document. Chunking delicate; Ideally, chunk stand alone without relying context surrounding document. can aim split text natural points like headings paragraphs, avoid splits middle sentence word. Additionally, can augment chunks context describes chunk’s origin–URL, title, headings, subheadings–LLM can provide links back source, LLM embedding models can better situate chunk’s content. help tasks, use markdown_chunk(). markdown_chunk() splits document chunks nudges chunk’s edges nearest semantic break. default, chunk 1,600 characters–roughly one page–50% overlap chunks. markdown_chunk also extracts markdown headings scope chunk start. headings added context embedding retrieval, helping LLM produce better answers. can specify chunking boundaries markdown_chunk()’s segment_by_heading_levels argument, takes vector integers 1 6. Chunks overlap defined segment boundary. Note alternative approach augmenting chunks context can use LLM instructions “situate excerpt document,” , worse, “summarize document.” can work carries significant risk. Remember, goal create knowledge store–trusted, factual, vetted source truth. Giving LLM opportunity corrupt store hallucinations may necessary depending needs, initial approximation, recommend starting ingestion pipeline give opportunities hallucinations enter store.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"insert-in-the-store","dir":"Articles","previous_headings":"Getting Started with ragnar > Setting up RAG","what":"Insert in the Store","title":"ragnar","text":"Take augmented document chunks insert store calling ragnar_store_insert(). function automatically generate embeddings using embed function specified store first created.","code":"ragnar_store_insert(store, chunks)"},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"tying-it-together","dir":"Articles","previous_headings":"Getting Started with ragnar > Setting up RAG","what":"Tying it Together","title":"ragnar","text":"Repeat steps every document want insert store. ’re done processing documents, call ragnar_store_build_index() finalize store build index. store index built, store ready retrieval.","code":"for (path in paths) {   chunks <- path |>     read_as_markdown() |>     markdown_chunk()   ragnar_store_insert(store, chunks) }  ragnar_store_build_index(store)"},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"retrieval","dir":"Articles","previous_headings":"Getting Started with ragnar","what":"Retrieval","title":"ragnar","text":"retrieve content store, call ragnar_retrieve(). function uses two retrieval methods: Vector similarity search (vss): Retrieves chunks whose embeddings similar query embedding. semantic search, used find content conceptually related query, even different words used. BM25: Retrieves chunks based keyword matching, using techniques like stemming term frequency. conventional text search, used find content containing specific words phrases. limit search one method, use ragnar_retrieve_vss() ragnar_retrieve_bm25(). can register ragnar_retrieve() LLM tool. effective technique implementing RAG, allows LLM rephrase unclear questions, ask follow-questions, search needed. Register ragnar_retrieve() tool ellmer::Chat using ragnar_register_tool_retrieve(): Note registered tool intentionally simple. asks LLM provide one argument: query string. LLM tool calls just text completions , like LLM output. minimize complexity tool interface minimize opportunities LLM make errors. Rather exposing detailed search options LLM, can instead set high top_k value return chunks usually necessary. provides slack chat app, can gracefully handle less--perfectly-ranked search results.","code":"client <- ellmer::chat_openai() ragnar_register_tool_retrieve(   client, store, top_k = 10,   description = \"the quarto website\" )"},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"customizing-retrieval","dir":"Articles","previous_headings":"Getting Started with ragnar > Retrieval","what":"Customizing Retrieval","title":"ragnar","text":"context-specific tasks, may want define retrieval tool pair system prompt explains use results. example, suppose want LLM perform repeated searches first search return relevant information, also want ensure repeated searches return previously seen chunks. ’s example might First, set system prompt: Next, define custom tool: approach presents retrieved content directly json. Presenting content defined structure helps prevent LLM confusing retrieved content user queries, confusing chunk metadata (like headings origin) chunk text. row-oriented format also ensures metadata (headings) stays attached row, context chunk appears next content. Register custom tool:","code":"client <- chat_openai(model = \"gpt-4.1\") client$set_system_prompt(glue::trim(   \"   You are an expert in Quarto documentation. You are concise.   Always perform a search of the Quarto knowledge store for each user request.   If the initial search does not return relevant documents, you may perform   up to three additional searches. Each search will return unique, new excerpts.   If no relevant results are found, inform the user and do not attempt to answer the question.   If the user request is ambiguous, perform at least one search first, then ask a clarifying question.    Every response must cite links to official documentation sources.   Always include a minimal, fully self-contained Quarto document in your answer.   \" )) rag_retrieve_quarto_excerpts <- local({   retrieved_chunk_ids <- integer()   function(text) {     # Search, excluding previously seen chunks     chunks <- ragnar::ragnar_retrieve(       text,       top_k = 10,       filter = !.data$chunk_id %in% retrieved_chunk_ids     )      # Update seen chunks     retrieved_chunk_ids <<- unique(unlist(c(retrieved_chunk_ids, chunks$chunk_id)))      # Return the chunks dataframe directly;     # ellmer will format this to json as a row-oriented list of objects.     chunks   } }) client$register_tool(ellmer::tool(   rag_retrieve_quarto_excerpts,   glue::trim(     \"     Use this tool to retrieve the most relevant excerpts from the Quarto     knowledge store for a given text input. This function:     - uses both vector (semantic) similarity and BM25 text search,     - never returns the same excerpt twice in the same session     \"   ),   text = ellmer::type_string() ))"},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"troubleshooting-and-debugging","dir":"Articles","previous_headings":"Getting Started with ragnar","what":"Troubleshooting and Debugging","title":"ragnar","text":"Developing RAG app iterative process. many places potentially spend effort improvements: selecting sources converting markdown chunking augmenting chunks using metadata narrow search choice embedding model choice LLM system prompt tool definition ’s helpful iterate context end--end application. can use ragnar_store_inspect() interactively see kinds results returned store different queries. helps confirm chunking augmentation preserve semantic meaning embedding model working expected. results shown inspector seem useful relevant , likely won’t useful LLM either. Iterate store creation pipeline retrieval returns meaningful excerpts.  things can try: Increase chunk size. Specify coarser custom boundaries markdown_chunk(). Augment chunks additional context. Try different embedding model. Try different LLM. Increase top_k return results. Iterate LLM system prompt give clearer, precise instructions. access store data directly, use tbl(store@con, \"chunks\"). store version 2, can also access tbl(store@con, \"documents\"). can use dbplyr verbs operate remote tbl, convert -memory tibble dplyr::collect(). Chat interfaces LLM marketing invite us think LLMs general-purpose agents, able answer anything. practice, however, 2025, building reliable, accurate, LLM-powered solution details facts matter means carefully scoping model responsible . mind, note chat app described intend replace documentation act general-purpose assistant. goal provide faster, contextual way find right place docs, enough information user decide need read . ’s designed allow users naturally escalate: LLM able provide useful answer, user can use provided links transition reading source material without friction.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"cost-management","dir":"Articles","previous_headings":"Getting Started with ragnar","what":"Cost Management","title":"ragnar","text":"Using LLMs embeddings incurs costs, regardless whether use commercial provider open source model hardware. tips managing costs: Use model large context window can include context, necessarily expensive reasoning model. RAG, summarization paraphrasing typically need flagship reasoning models return useful results. cost generating embeddings negligible. example, generating embeddings entire Quarto website costs approximately cent. Keep chat sessions focused concise. Start new chat sessions unrelated questions. Long conversations increase token usage, costs, practice, also lower output quality LLM gets confused stale irrelevant conversation turns. reference, flagship OpenAI model ‘gpt-4.1’, query RAG-powered chat app like quartohelp costs approximately 1 cent.","code":""},{"path":"https://ragnar.tidyverse.org/dev/articles/ragnar.html","id":"summary","dir":"Articles","previous_headings":"Getting Started with ragnar","what":"Summary","title":"ragnar","text":"ragnar provides practical, transparent way build RAG workflows R. combining semantic keyword search, clear chunking augmentation, focused prompt tool design, can create fast, interactive documentation chat tools help users find answers quickly reliably. Building good RAG system iterative. Inspect intermediate outputs, tune chunking retrieval, keep user’s workflow mind. guardrails, can reduce hallucinations deliver trustworthy, grounded answers–also giving users path original source. details full example, see quartohelp package.","code":""},{"path":"https://ragnar.tidyverse.org/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tomasz Kalinowski. Author, maintainer. Daniel Falbel. Author. . Copyright holder, funder.","code":""},{"path":"https://ragnar.tidyverse.org/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kalinowski T, Falbel D (2025). ragnar: Retrieval-Augmented Generation (RAG) Workflows. R package version 0.2.1.9000, https://ragnar.tidyverse.org/.","code":"@Manual{,   title = {ragnar: Retrieval-Augmented Generation (RAG) Workflows},   author = {Tomasz Kalinowski and Daniel Falbel},   year = {2025},   note = {R package version 0.2.1.9000},   url = {https://ragnar.tidyverse.org/}, }"},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"ragnar-","dir":"","previous_headings":"","what":"Retrieval-Augmented Generation (RAG) Workflows","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"ragnar R package helps implement Retrieval-Augmented Generation (RAG) workflows. focuses providing complete solution sensible defaults, still giving knowledgeable user precise control step. don’t believe can fully automate creation good RAG system, ’s important ragnar black box. ragnar designed transparent. can easily inspect outputs intermediate steps understand ’s happening.","code":""},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"can install ragnar CRAN : can install development version GitHub :","code":"install.packages(\"ragnar\") # install.packages(\"pak\") pak::pak(\"tidyverse/ragnar\")"},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"id_1-document-processing","dir":"","previous_headings":"Key Steps","what":"1. Document Processing","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"ragnar works wide variety document types, using MarkItDown convert content Markdown. Key functions: read_as_markdown(): Convert file URL markdown ragnar_find_links(): Find links webpage","code":""},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"id_2-text-chunking","dir":"","previous_headings":"Key Steps","what":"2. Text Chunking","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"Next divide document chunks. Ragnar defaults strategy preserves semantics document, provides plenty opportunities tweak approach. Key functions: markdown_chunk(): Full-featured chunker identifies semantic boundaries intelligently chunks text.","code":""},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"id_3-context-augmentation-optional","dir":"","previous_headings":"Key Steps","what":"3. Context Augmentation (Optional)","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"RAG applications benefit augmenting text chunks additional context, document headings subheadings. ragnar makes easy keep track headings subheadings part chunking. markdown_chunk() automatically associates chunk headings scope chunk.","code":""},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"id_4-embedding","dir":"","previous_headings":"Key Steps","what":"4. Embedding","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"ragnar can help compute embeddings chunk. goal ragnar provide access embeddings popular LLM providers. Key functions: embed_ollama() embed_openai() embed_bedrock() embed_databricks() embed_google_vertex() Note calling embedding function directly typically necessary. Instead, embedding function specified store first created, automatically called needed ragnar_retrieve() ragnar_store_insert().","code":""},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"id_5-storage","dir":"","previous_headings":"Key Steps","what":"5. Storage","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"Processed data stored format optimized efficient searching, using duckdb default. API designed extensible, allowing additional packages implement support different storage providers. Key functions: ragnar_store_create() ragnar_store_connect() ragnar_store_insert()","code":""},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"id_6-retrieval","dir":"","previous_headings":"Key Steps","what":"6. Retrieval","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"Given prompt, retrieve related chunks based embedding distance bm25 text search. Key functions: ragnar_retrieve(): high-level function performs vss bm25 search de-overlaps retrieved results. ragnar_retrieve_vss(): Retrieve using vss DuckDB extension ragnar_retrieve_bm25(): Retrieve using full-text search DuckDB extension chunks_deoverlap(): Consolidates retrieved chunks overlap.","code":""},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"id_7-chat-augmentation","dir":"","previous_headings":"Key Steps","what":"7. Chat Augmentation","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"ragnar can equip ellmer::Chat object retrieve tool enables LLM retrieve content store -demand. ragnar_register_tool_retrieve(chat, store).","code":""},{"path":"https://ragnar.tidyverse.org/dev/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Retrieval-Augmented Generation (RAG) Workflows","text":"’s example using ragnar create knowledge store R Data Science (2e) book: store set , can retrieve relevant text chunks.","code":"library(ragnar)  base_url <- \"https://r4ds.hadley.nz\" pages <- ragnar_find_links(base_url)  store_location <- \"r4ds.ragnar.duckdb\"  store <- ragnar_store_create(   store_location,   embed = \\(x) ragnar::embed_openai(x, model = \"text-embedding-3-small\") )  for (page in pages) {   message(\"ingesting: \", page)   chunks <- page |> read_as_markdown() |> markdown_chunk()   ragnar_store_insert(store, chunks) } #> ingesting: https://r4ds.hadley.nz/ #> ingesting: https://r4ds.hadley.nz/arrow.html #> ingesting: https://r4ds.hadley.nz/base-R.html #> ingesting: https://r4ds.hadley.nz/communicate.html #> ingesting: https://r4ds.hadley.nz/communication.html #> ingesting: https://r4ds.hadley.nz/data-import.html #> ingesting: https://r4ds.hadley.nz/data-tidy.html #> ingesting: https://r4ds.hadley.nz/data-transform.html #> ingesting: https://r4ds.hadley.nz/data-visualize.html #> ingesting: https://r4ds.hadley.nz/databases.html #> ingesting: https://r4ds.hadley.nz/datetimes.html #> ingesting: https://r4ds.hadley.nz/EDA.html #> ingesting: https://r4ds.hadley.nz/factors.html #> ingesting: https://r4ds.hadley.nz/functions.html #> ingesting: https://r4ds.hadley.nz/import.html #> ingesting: https://r4ds.hadley.nz/intro.html #> ingesting: https://r4ds.hadley.nz/iteration.html #> ingesting: https://r4ds.hadley.nz/joins.html #> ingesting: https://r4ds.hadley.nz/layers.html #> ingesting: https://r4ds.hadley.nz/logicals.html #> ingesting: https://r4ds.hadley.nz/missing-values.html #> ingesting: https://r4ds.hadley.nz/numbers.html #> ingesting: https://r4ds.hadley.nz/preface-2e.html #> ingesting: https://r4ds.hadley.nz/program.html #> ingesting: https://r4ds.hadley.nz/quarto-formats.html #> ingesting: https://r4ds.hadley.nz/quarto.html #> ingesting: https://r4ds.hadley.nz/rectangling.html #> ingesting: https://r4ds.hadley.nz/regexps.html #> ingesting: https://r4ds.hadley.nz/spreadsheets.html #> ingesting: https://r4ds.hadley.nz/strings.html #> ingesting: https://r4ds.hadley.nz/transform.html #> ingesting: https://r4ds.hadley.nz/visualize.html #> ingesting: https://r4ds.hadley.nz/webscraping.html #> ingesting: https://r4ds.hadley.nz/whole-game.html #> ingesting: https://r4ds.hadley.nz/workflow-basics.html #> ingesting: https://r4ds.hadley.nz/workflow-help.html #> ingesting: https://r4ds.hadley.nz/workflow-scripts.html #> ingesting: https://r4ds.hadley.nz/workflow-style.html  ragnar_store_build_index(store) #' ## Retrieving Chunks  library(ragnar) store_location <- \"r4ds.ragnar.duckdb\" store <- ragnar_store_connect(store_location, read_only = TRUE)  text <- \"How can I subset a dataframe with a logical vector?\"   #' # Retrieving Chunks #' Once the store is set up, retrieve the most relevant text chunks like this  (relevant_chunks <- ragnar_retrieve(store, text)) #> # A tibble: 4 × 9 #>   origin         doc_id chunk_id start   end cosine_distance bm25  context text  #>   <chr>           <int> <list>   <int> <int> <list>          <lis> <chr>   <chr> #> 1 https://r4ds.…     14 <int>     2192  4007 <dbl [1]>       <dbl> \"# 25 … \"```… #> 2 https://r4ds.…     20 <int>     1622  4205 <dbl [2]>       <dbl> \"# 12 … \"```… #> 3 https://r4ds.…     20 <int>    19379 20792 <dbl [1]>       <dbl> \"# 12 … \"Tha… #> 4 https://r4ds.…     33 <int>    12795 15259 <dbl [2]>       <dbl> \"# 24 … \"The… #'  Register ellmer tool #' You can register an ellmer tool to let the LLM retrieve chunks. system_prompt <- stringr::str_squish(   \"   You are an expert R programmer and mentor. You are concise.    Before responding, retrieve relevant material from the knowledge store. Quote or   paraphrase passages, clearly marking your own words versus the source. Provide a   working link for every source cited, as well as any additional relevant links.   Do not answer unless you have retrieved and cited a source.   \" ) chat <- ellmer::chat_openai(   system_prompt,   model = \"gpt-4.1\" )  ragnar_register_tool_retrieve(chat, store, top_k = 10)  chat$chat(\"How can I subset a dataframe?\") #> ◯ [tool call] rag_retrieve_from_store_001(text = \"How to subset a dataframe in #> R\") #> ● #> [{\"origin\":\"https://r4ds.hadley.nz/arrow.html\",\"doc_id\":2,\"chunk_id\":13,\"… #> To subset a dataframe in R, you can use several approaches, such as base R or  #> dplyr. Here are some concise examples: #>  #> Base R: #> - Select rows and columns by indices or names: df[rows, cols] #> Example: #> ```r #> df[1:3, c(\"x\", \"y\")]  # First 3 rows, columns x and y #> ``` #> - Subset by logical condition: #> ```r #> df[df$x > 1, ]  # Rows where column x > 1 #> ``` #> - Select columns only: df[, c(\"x\", \"y\")] #> - Select rows only: df[1:5, ] #> (Source: https://r4ds.hadley.nz/base-R.html#subsetting-data-frames) #>  #> dplyr package: #> - Subset rows: filter(), select columns: select() #> Example: #> ```r #> library(dplyr) #> df %>% filter(x > 1) %>% select(x, y) #> ``` #> (Source: https://r4ds.hadley.nz/functions.html#common-use-cases) #>  #> You can also use the base R subset() function: #> ```r #> subset(df, x > 1, select = c(x, y)) #> ``` #> (Source: https://r4ds.hadley.nz/base-R.html#subsetting-data-frames) #>  #> References: #> - https://r4ds.hadley.nz/base-R.html#subsetting-data-frames #> - https://r4ds.hadley.nz/functions.html#common-use-cases #>  #> Further reading: #> - dplyr filter(): https://dplyr.tidyverse.org/reference/filter.html #> - dplyr select(): https://dplyr.tidyverse.org/reference/select.html"},{"path":"https://ragnar.tidyverse.org/dev/reference/MarkdownDocument.html","id":null,"dir":"Reference","previous_headings":"","what":"Markdown documents — MarkdownDocument","title":"Markdown documents — MarkdownDocument","text":"MarkdownDocument represents complete Markdown document stored single character string. constructor normalizes text collapsing lines ensuring UTF-8 encoding, downstream code can rely consistent format. read_as_markdown() recommended way create MarkdownDocument. constructor exported advanced users can construct one means needed.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/MarkdownDocument.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Markdown documents — MarkdownDocument","text":"text [string] Markdown text. origin [string] Optional source path URL. Defaults \"origin\" attribute text, present, otherwise NULL.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/MarkdownDocument.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Markdown documents — MarkdownDocument","text":"S7 object inherits MarkdownDocument, length 1 string markdown text @origin property.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/MarkdownDocument.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Markdown documents — MarkdownDocument","text":"","code":"md <- MarkdownDocument(   \"# Title\\n\\nSome text.\",   origin = \"example.md\" ) md #> <ragnar::MarkdownDocument> chr \"# Title\\n\\nSome text.\" #>  @ origin: chr \"example.md\""},{"path":"https://ragnar.tidyverse.org/dev/reference/MarkdownDocumentChunks.html","id":null,"dir":"Reference","previous_headings":"","what":"Markdown documents chunks — MarkdownDocumentChunks","title":"Markdown documents chunks — MarkdownDocumentChunks","text":"MarkdownDocumentChunks stores information candidate chunks Markdown document. tibble three required columns: start, end — integers. character positions (1-based, inclusive) source MarkdownDocument, substring(md, start, end) yields chunk text. Ranges can overlap. context — character. general-purpose field adding context chunk. column combined text augment chunk content generating embeddings ragnar_store_insert(), also returned ragnar_retrieve(). Keep mind chunks deoverlapped (ragnar_retrieve() chunks_deoverlap()), context value first chunk kept. markdown_chunk() default populates column markdown headings -scope chunk start position. Additional columns can included. original document available via @document property. normal use, chunk Markdown document markdown_chunk(); class constructor exported advanced users can generate tweak chunks means.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/MarkdownDocumentChunks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Markdown documents chunks — MarkdownDocumentChunks","text":"chunks data frame containing start, end, context columns, optionally columns. document MarkdownDocument.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/MarkdownDocumentChunks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Markdown documents chunks — MarkdownDocumentChunks","text":"S7 object inherits MarkdownDocumentChunks, also tibble.","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/MarkdownDocumentChunks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Markdown documents chunks — MarkdownDocumentChunks","text":"","code":"doc_text <- \"# A\\n\\nB\\n\\n## C\\n\\nD\" # can be readLines() output, etc. doc <- MarkdownDocument(doc_text, origin = \"some/where\") chunk_positions <- tibble::tibble(   start = c(1L, 9L),   end = c(8L, 15L),   context = c(\"\", \"# A\"),   text = substring(doc, start, end) ) chunks <- MarkdownDocumentChunks(chunk_positions, doc) identical(chunks@document, doc) #> [1] TRUE"},{"path":"https://ragnar.tidyverse.org/dev/reference/chunks_deoverlap.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge overlapping chunks in retrieved results — chunks_deoverlap","title":"Merge overlapping chunks in retrieved results — chunks_deoverlap","text":"Groups merges overlapping text chunks origin retrieval results.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/chunks_deoverlap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge overlapping chunks in retrieved results — chunks_deoverlap","text":"","code":"chunks_deoverlap(store, chunks)"},{"path":"https://ragnar.tidyverse.org/dev/reference/chunks_deoverlap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge overlapping chunks in retrieved results — chunks_deoverlap","text":"store RagnarStore object. Must @version == 2. chunks tibble retrieved chunks, output ragnar_retrieve().","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/chunks_deoverlap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge overlapping chunks in retrieved results — chunks_deoverlap","text":"tibble de-overlapped chunks.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/chunks_deoverlap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Merge overlapping chunks in retrieved results — chunks_deoverlap","text":"multiple retrieved chunks origin overlapping character ranges, function combines single non-overlapping region.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_azure_openai.html","id":null,"dir":"Reference","previous_headings":"","what":"Uses Azure AI Foundry to create embeddings — embed_azure_openai","title":"Uses Azure AI Foundry to create embeddings — embed_azure_openai","text":"Uses Azure AI Foundry create embeddings","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_azure_openai.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uses Azure AI Foundry to create embeddings — embed_azure_openai","text":"","code":"embed_azure_openai(   x,   endpoint = get_envvar(\"AZURE_OPENAI_ENDPOINT\"),   api_key = get_envvar(\"AZURE_OPENAI_API_KEY\"),   api_version = \"2023-05-15\",   model,   batch_size = 20L,   api_args = list() )"},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_azure_openai.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uses Azure AI Foundry to create embeddings — embed_azure_openai","text":"x x can : character vector, case matrix embeddings returned. data frame column named text, case dataframe returned additional column named embedding. Missing NULL, case function returned can called get embeddings. convenient way partial additional arguments like model, convenient way produce function can passed embed argument ragnar_store_create(). endpoint Azure AI Foundry endpoint URL. URI form https://<project>.cognitiveservices.azure.com/. Defaults value AZURE_OPENAI_ENDPOINT environment variable. URL appended /openai/deployments/{model}/embeddings. model deployment name model. api_key resolved using env var OPENAI_API_KEY api_version API version use. Defaults 2023-05-15. model deployment name model use generating embeddings. batch_size split x batches embedding. Integer, limit strings include single request. api_args list additional arguments pass API request body.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_azure_openai.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uses Azure AI Foundry to create embeddings — embed_azure_openai","text":"x character vector, numeric matrix returned, nrow = length(x) ncol = <model-embedding-size>. x data.frame, new embedding matrix \"column\" added, containing matrix described previous sentence. matrix embeddings 1 row per input string, dataframe 'embedding' column.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_bedrock.html","id":null,"dir":"Reference","previous_headings":"","what":"Embed text using a Bedrock model — embed_bedrock","title":"Embed text using a Bedrock model — embed_bedrock","text":"Embed text using Bedrock model","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_bedrock.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embed text using a Bedrock model — embed_bedrock","text":"","code":"embed_bedrock(x, model, profile, api_args = list())"},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_bedrock.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embed text using a Bedrock model — embed_bedrock","text":"x x can : character vector, case matrix embeddings returned. data frame column named text, case dataframe returned additional column named embedding. Missing NULL, case function returned can called get embeddings. convenient way partial additional arguments like model, convenient way produce function can passed embed argument ragnar_store_create(). model Currently Cohere.ai Amazon Titan models supported. guardarails kind model used, model must available AWS region specified profile. may look available models Bedrock Model Catalog profile AWS profile use. api_args Additional arguments pass Bedrock API. Depending model, might able provide different parameters. Check documentation model using Bedrock user guide.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_bedrock.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embed text using a Bedrock model — embed_bedrock","text":"x missing returns function can called get embeddings. x missing, matrix embeddings 1 row per input string, dataframe 'embedding' column.","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_databricks.html","id":null,"dir":"Reference","previous_headings":"","what":"Embed text using a Databricks model — embed_databricks","title":"Embed text using a Databricks model — embed_databricks","text":"embed_databricks() gets embeddings text using model hosted Databricks workspace. relies ellmer package managing Databricks credentials. See ellmer::chat_databricks supported modes authentication.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_databricks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embed text using a Databricks model — embed_databricks","text":"","code":"embed_databricks(   x,   workspace = databricks_workspace(),   model = \"databricks-bge-large-en\",   batch_size = 512L )"},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_databricks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embed text using a Databricks model — embed_databricks","text":"x x can : character vector, case matrix embeddings returned. data frame column named text, case dataframe returned additional column named embedding. Missing NULL, case function returned can called get embeddings. convenient way partial additional arguments like model, convenient way produce function can passed embed argument ragnar_store_create(). workspace URL Databricks workspace, e.g. \"https://example.cloud.databricks.com\". use value environment variable DATABRICKS_HOST, set. model name text embedding model. batch_size split x batches embedding. Integer, limit strings include single request.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_google_vertex.html","id":null,"dir":"Reference","previous_headings":"","what":"Embed using Google Vertex API platform — embed_google_gemini","title":"Embed using Google Vertex API platform — embed_google_gemini","text":"Embed using Google Vertex API platform","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_google_vertex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embed using Google Vertex API platform — embed_google_gemini","text":"","code":"embed_google_gemini(   x,   model = \"gemini-embedding-001\",   base_url = \"https://generativelanguage.googleapis.com/v1beta\",   api_key = get_envvar(\"GEMINI_API_KEY\"),   dims = NULL,   task_type = \"RETRIEVAL_QUERY\",   batch_size = 20L )  embed_google_vertex(   x,   model,   location,   project_id,   task_type = \"RETRIEVAL_QUERY\" )"},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_google_vertex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embed using Google Vertex API platform — embed_google_gemini","text":"x x can : character vector, case matrix embeddings returned. data frame column named text, case dataframe returned additional column named embedding. Missing NULL, case function returned can called get embeddings. convenient way partial additional arguments like model, convenient way produce function can passed embed argument ragnar_store_create(). model Character specifying embedding model. See supported models Text embeddings API base_url string, url service available. api_key resolved using env var GEMINI_API_KEY dims integer, can used truncate embedding specific size. task_type Used convey intended downstream application help model produce better embeddings. left blank, default used \"RETRIEVAL_QUERY\". \"RETRIEVAL_QUERY\" \"RETRIEVAL_DOCUMENT\" \"SEMANTIC_SIMILARITY\" \"CLASSIFICATION\" \"CLUSTERING\" \"QUESTION_ANSWERING\" \"FACT_VERIFICATION\" \"CODE_RETRIEVAL_QUERY\" information task types, see Choose embeddings task type. batch_size split x batches embedding. Integer, limit strings include single request. location Location, e.g. us-east1, -central1, africa-south1 global. project_id Project ID.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_google_vertex.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Embed using Google Vertex API platform — embed_google_gemini","text":"embed_google_gemini(): Use Gemini API create embeddings.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_google_vertex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embed using Google Vertex API platform — embed_google_gemini","text":"","code":"if (FALSE) { # Sys.getenv(\"GEMINI_API_KEY\") != \"\" embed_google_gemini(\"hello world\") } # \\dontrun{ embed_google_vertex(  \"hello world\",  model=\"gemini-embedding-001\",  project = \"<your-project-id>\",  location = \"us-central1\" ) #> Error in embed_google_vertex(\"hello world\", model = \"gemini-embedding-001\",     project = \"<your-project-id>\", location = \"us-central1\"): No Google credentials are available. #> ℹ Try suppling an API key or configuring Google's application default #>   credentials. # }"},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_ollama.html","id":null,"dir":"Reference","previous_headings":"","what":"Embed Text — embed_ollama","title":"Embed Text — embed_ollama","text":"Embed Text","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_ollama.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embed Text — embed_ollama","text":"","code":"embed_ollama(   x,   base_url = \"http://localhost:11434\",   model = \"embeddinggemma:300m\",   batch_size = 10L )  embed_openai(   x,   model = \"text-embedding-3-small\",   base_url = \"https://api.openai.com/v1\",   api_key = get_envvar(\"OPENAI_API_KEY\"),   dims = NULL,   user = get_user(),   batch_size = 20L )  embed_lm_studio(   x,   model,   base_url = \"http://localhost:1234/v1\",   api_key = \"lm-studio\",   dims = NULL,   user = get_user(),   batch_size = 20L )"},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_ollama.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embed Text — embed_ollama","text":"x x can : character vector, case matrix embeddings returned. data frame column named text, case dataframe returned additional column named embedding. Missing NULL, case function returned can called get embeddings. convenient way partial additional arguments like model, convenient way produce function can passed embed argument ragnar_store_create(). base_url string, url service available. model string; model name batch_size split x batches embedding. Integer, limit strings include single request. api_key resolved using env var OPENAI_API_KEY dims integer, can used truncate embedding specific size. user User name passed via API.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_ollama.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embed Text — embed_ollama","text":"x character vector, numeric matrix returned, nrow = length(x) ncol = <model-embedding-size>. x data.frame, new embedding matrix \"column\" added, containing matrix described previous sentence. matrix embeddings 1 row per input string, dataframe 'embedding' column.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_ollama.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Embed Text — embed_ollama","text":"embed_lm_studio(): Embed Text using LMStudio. Indentical embed_openai() suitable defaults LMStudio.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/embed_ollama.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embed Text — embed_ollama","text":"","code":"text <- c(\"a chunk of text\", \"another chunk of text\", \"one more chunk of text\") # \\dontrun{ text |>   embed_ollama() |>   str() #> Error in req_perform(req): Failed to perform HTTP request. #> Caused by error in `curl::curl_fetch_memory()`: #> ! Couldn't connect to server [localhost]: #> Failed to connect to localhost port 11434 after 0 ms: Couldn't connect to server  text |>   embed_openai() |>   str() #> Error in embed_openai(text): Can't find env var `OPENAI_API_KEY`. # }"},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_chunk.html","id":null,"dir":"Reference","previous_headings":"","what":"Chunk a Markdown document — markdown_chunk","title":"Chunk a Markdown document — markdown_chunk","text":"markdown_chunk() splits single Markdown string shorter optionally overlapping chunks nudging cut points nearest sensible boundary (heading, paragraph, sentence, line, word, character). returns tibble recording character ranges, headings context, text chunk.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_chunk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chunk a Markdown document — markdown_chunk","text":"","code":"markdown_chunk(   md,   target_size = 1600L,   target_overlap = 0.5,   ...,   max_snap_dist = target_size * (1 - target_overlap)/3,   segment_by_heading_levels = integer(),   context = TRUE,   text = TRUE )"},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_chunk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chunk a Markdown document — markdown_chunk","text":"md MarkdownDocument, length-one character vector containing Markdown. target_size Integer. Target chunk size characters. Default: 1600 (\\(\\approx\\) 400 tokens, 1 page text). Actual chunk size may differ target 2 * max_snap_dist. set NULL, NA Inf used segment_by_heading_levels, chunk size unbounded chunk corresponds segment. target_overlap Numeric [0, 1). Fraction desired overlap successive chunks. Default: 0.5. Even 0, overlap can occur last chunk anchored document end. ... dots future extensions must empty. max_snap_dist Integer. Furthest distance (characters) cut point may move reach semantic boundary. Defaults one third stride size target chunk starts. Chunks end identical boundaries merged. segment_by_heading_levels Integer vector possible values 1:6. Headings levels treated segment boundaries; chunking performed independently segment. chunk overlap segment boundary, future deoverlapping combine segments. segment chunk starts segment start chunk ends segment end (may chunk overlap substantially segment short). Default: disabled. context Logical. Add context column containing Markdown headings scope chunk start. Default: TRUE. text Logical. TRUE, include text column chunk contents. Default: TRUE.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_chunk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chunk a Markdown document — markdown_chunk","text":"MarkdownDocumentChunks object, tibble (data.frame) columns start end, optionally context text. also @document property, input md document (potentially normalized converted MarkdownDocument).","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_chunk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chunk a Markdown document — markdown_chunk","text":"","code":"md <- \" # Title  ## Section 1  Some text that is long enough to be chunked.  A second paragraph to make the text even longer.  ## Section 2  More text here.  ### Section 2.1  Some text under a level three heading.  #### Section 2.1.1  Some text under a level four heading.  ## Section 3  Even more text here. \"  markdown_chunk(md, target_size = 40) #> # A tibble: 15 × 4 #>    start   end context                                            text  #>  * <int> <int> <chr>                                              <chr> #>  1     1    39 \"\"                                                 \"\\n#… #>  2    25    60 \"# Title\\n## Section 1\"                            \"Som… #>  3    40    79 \"# Title\\n## Section 1\"                            \"is … #>  4    61   101 \"# Title\\n## Section 1\"                            \"chu… #>  5    80   120 \"# Title\\n## Section 1\"                            \"par… #>  6   102   134 \"# Title\\n## Section 1\"                            \"tex… #>  7   121   166 \"# Title\"                                          \"## … #>  8   135   178 \"# Title\\n## Section 2\"                            \"Mor… #>  9   167   206 \"# Title\\n## Section 2\\n### Section 2.1\"           \"\\n\\… #> 10   179   226 \"# Title\\n## Section 2\\n### Section 2.1\"           \"und… #> 11   207   238 \"# Title\\n## Section 2\\n### Section 2.1\"           \"\\n\\… #> 12   227   266 \"# Title\\n## Section 2\\n### Section 2.1\\n#### Sec… \"\\n\\… #> 13   239   281 \"# Title\\n## Section 2\\n### Section 2.1\\n#### Sec… \"und… #> 14   267   301 \"# Title\\n## Section 2\\n### Section 2.1\\n#### Sec… \"\\n#… #> 15   268   302 \"# Title\"                                          \"## … markdown_chunk(md, target_size = 40, target_overlap = 0) #> # A tibble: 8 × 4 #>   start   end context                                             text  #> * <int> <int> <chr>                                               <chr> #> 1     1    39 \"\"                                                  \"\\n#… #> 2    40    70 \"# Title\\n## Section 1\"                             \"is … #> 3    71   120 \"# Title\\n## Section 1\"                             \"A s… #> 4   121   151 \"# Title\"                                           \"## … #> 5   152   208 \"# Title\\n## Section 2\"                             \"###… #> 6   209   228 \"# Title\\n## Section 2\\n### Section 2.1\"            \"###… #> 7   229   267 \"# Title\\n## Section 2\\n### Section 2.1\\n#### Sect… \"Som… #> 8   268   302 \"# Title\"                                           \"## … markdown_chunk(md, target_size = NA, segment_by_heading_levels = c(1, 2)) #> # A tibble: 5 × 4 #>   start   end context   text                                            #> * <int> <int> <chr>     <chr>                                           #> 1     1     1 \"\"        \"\\n\"                                            #> 2     2    10 \"\"        \"# Title\\n\\n\"                                   #> 3    11   120 \"# Title\" \"## Section 1\\n\\nSome text that is long enough… #> 4   121   267 \"# Title\" \"## Section 2\\n\\nMore text here.\\n\\n### Sectio… #> 5   268   302 \"# Title\" \"## Section 3\\n\\nEven more text here.\\n\"        markdown_chunk(md, target_size = 40, max_snap_dist = 100) #> # A tibble: 6 × 4 #>   start   end context                                  text             #> * <int> <int> <chr>                                    <chr>            #> 1     1    10 \"\"                                       \"\\n# Title\\n\\n\"  #> 2    11   120 \"# Title\"                                \"## Section 1\\n… #> 3   121   151 \"# Title\"                                \"## Section 2\\n… #> 4   152   208 \"# Title\\n## Section 2\"                  \"### Section 2.… #> 5   209   267 \"# Title\\n## Section 2\\n### Section 2.1\" \"#### Section 2… #> 6   268   302 \"# Title\"                                \"## Section 3\\n…"},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_segment.html","id":null,"dir":"Reference","previous_headings":"","what":"Segment markdown text — markdown_segment","title":"Segment markdown text — markdown_segment","text":"Segment markdown text","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_segment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Segment markdown text — markdown_segment","text":"","code":"markdown_segment(   text,   tags = c(\"h1\", \"h2\", \"h3\", \"h4\"),   trim = FALSE,   omit_empty = FALSE )  markdown_frame(text, frame_by = c(\"h1\", \"h2\", \"h3\"), segment_by = NULL)"},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_segment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Segment markdown text — markdown_segment","text":"text Markdown string tags, segment_by character vector html tag names, e.g., c(\"h1\", \"h2\", \"h3\", \"pre\") trim logical, trim whitespace segments omit_empty logical, whether remove empty segments frame_by Character vector tags become columns returned dataframe.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_segment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Segment markdown text — markdown_segment","text":"named character vector. Names correspond tags, \"\" content tags.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/markdown_segment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Segment markdown text — markdown_segment","text":"","code":"md <- r\"---(  # Sample Markdown File  ## Introduction  This is a sample **Markdown** file for testing.  ### Features  - Simple **bold** text - _Italicized_ text - `Inline code` - A [link](https://example.com) - ‘Curly quotes are 3 bytes chars.’ Non-ascii text is fine.  This is a paragraph with <p> tag.  This next segment with code has a <pre> tag  ```r hello_world <- function() {   cat(\"Hello, World!\\n\") } ```  A table <table>:    | Name  | Age | City      |   |-------|----:|-----------|   | Alice |  25 | New York  |   | Bob   |  30 | London    |   ## Conclusion  Common tags:  - h1, h2, h3, h4, h5, h6: section headings - p: paragraph (prose) - pre: pre-formatted text, meant to be displayed with monospace font.   Typically code or code output - blockquote: A blockquote - table: A table - ul: Unordered list - ol: Ordered list - li: Individual list item in a <ul> or <ol>   )---\" markdown_segment(md) |> tibble::enframe() #> # A tibble: 9 × 2 #>   name  value                                                           #>   <chr> <chr>                                                           #> 1 \"\"    \"\\n\\n\"                                                          #> 2 \"h1\"  \"# Sample Markdown File\"                                        #> 3 \"\"    \"\\n\\n\"                                                          #> 4 \"h2\"  \"## Introduction\"                                               #> 5 \"\"    \"\\n\\nThis is a sample **Markdown** file for testing.\\n\\n\"       #> 6 \"h3\"  \"### Features\"                                                  #> 7 \"\"    \"\\n\\n- Simple **bold** text\\n- _Italicized_ text\\n- `Inline co… #> 8 \"h2\"  \"## Conclusion\"                                                 #> 9 \"\"    \"\\n\\nCommon tags:\\n\\n- h1, h2, h3, h4, h5, h6: section heading… markdown_segment(md |> trimws()) |> tibble::enframe() #> # A tibble: 8 × 2 #>   name  value                                                           #>   <chr> <chr>                                                           #> 1 \"h1\"  \"# Sample Markdown File\"                                        #> 2 \"\"    \"\\n\\n\"                                                          #> 3 \"h2\"  \"## Introduction\"                                               #> 4 \"\"    \"\\n\\nThis is a sample **Markdown** file for testing.\\n\\n\"       #> 5 \"h3\"  \"### Features\"                                                  #> 6 \"\"    \"\\n\\n- Simple **bold** text\\n- _Italicized_ text\\n- `Inline co… #> 7 \"h2\"  \"## Conclusion\"                                                 #> 8 \"\"    \"\\n\\nCommon tags:\\n\\n- h1, h2, h3, h4, h5, h6: section heading… markdown_segment(md, c(\"li\"), trim = TRUE, omit_empty = TRUE) |> tibble::enframe() #> # A tibble: 15 × 2 #>    name  value                                                          #>    <chr> <chr>                                                          #>  1 \"\"    \"# Sample Markdown File\\n\\n## Introduction\\n\\nThis is a sampl… #>  2 \"li\"  \"- Simple **bold** text\"                                       #>  3 \"li\"  \"- _Italicized_ text\"                                          #>  4 \"li\"  \"- `Inline code`\"                                              #>  5 \"li\"  \"- A [link](https://example.com)\"                              #>  6 \"li\"  \"- ‘Curly quotes are 3 bytes chars.’ Non-ascii text is fine.\"  #>  7 \"\"    \"This is a paragraph with <p> tag.\\n\\nThis next segment with … #>  8 \"li\"  \"- h1, h2, h3, h4, h5, h6: section headings\"                   #>  9 \"li\"  \"- p: paragraph (prose)\"                                       #> 10 \"li\"  \"- pre: pre-formatted text, meant to be displayed with monosp… #> 11 \"li\"  \"- blockquote: A blockquote\"                                   #> 12 \"li\"  \"- table: A table\"                                             #> 13 \"li\"  \"- ul: Unordered list\"                                         #> 14 \"li\"  \"- ol: Ordered list\"                                           #> 15 \"li\"  \"- li: Individual list item in a <ul> or <ol>\"                 markdown_segment(md, c(\"table\"), trim = TRUE, omit_empty = TRUE) |> tibble::enframe() #> # A tibble: 3 × 2 #>   name    value                                                         #>   <chr>   <chr>                                                         #> 1 \"\"      \"# Sample Markdown File\\n\\n## Introduction\\n\\nThis is a samp… #> 2 \"table\" \"| Name  | Age | City      |\\n  |-------|----:|-----------|\\… #> 3 \"\"      \"## Conclusion\\n\\nCommon tags:\\n\\n- h1, h2, h3, h4, h5, h6: … markdown_segment(md, c(\"ul\"), trim = TRUE, omit_empty = TRUE) |> tibble::enframe() #> # A tibble: 4 × 2 #>   name  value                                                           #>   <chr> <chr>                                                           #> 1 \"\"    \"# Sample Markdown File\\n\\n## Introduction\\n\\nThis is a sample… #> 2 \"ul\"  \"- Simple **bold** text\\n- _Italicized_ text\\n- `Inline code`\\… #> 3 \"\"    \"This is a paragraph with <p> tag.\\n\\nThis next segment with c… #> 4 \"ul\"  \"- h1, h2, h3, h4, h5, h6: section headings\\n- p: paragraph (p…"},{"path":"https://ragnar.tidyverse.org/dev/reference/mcp_serve_store.html","id":null,"dir":"Reference","previous_headings":"","what":"Serve a Ragnar store over MCP — mcp_serve_store","title":"Serve a Ragnar store over MCP — mcp_serve_store","text":"Launches MCP server (via mcptools::mcp_server()) exposes retrieval tool backed Ragnar store. lets MCP-enabled clients (e.g., Codex CLI, Claude Code) call store retrieve relevant excerpts.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/mcp_serve_store.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Serve a Ragnar store over MCP — mcp_serve_store","text":"","code":"mcp_serve_store(   store,   store_description = \"the knowledge store\",   ...,   name = NULL,   title = NULL,   extra_tools = NULL )"},{"path":"https://ragnar.tidyverse.org/dev/reference/mcp_serve_store.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Serve a Ragnar store over MCP — mcp_serve_store","text":"store RagnarStore object file path Ragnar DuckDB store. character path supplied, opened ragnar_store_connect(). store_description Optional string used tool description presented clients. ... arguments passed ragnar_retrieve(). name, title Optional tool function name title. default, store@name store@title used present. tool name must valid R function name unique tools registered ellmer::Chat object. title used user-friendly display. extra_tools Optional additional tools (list ellmer::tool() objects) serve alongside retrieval tool.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/mcp_serve_store.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Serve a Ragnar store over MCP — mcp_serve_store","text":"function blocks current R process running MCP server. intended non-interactive use. Called primarily side-effects.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/mcp_serve_store.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Serve a Ragnar store over MCP — mcp_serve_store","text":"use function Codex CLI, add something like ~/.codex/config.toml   can confirm agent can search ragnar store inspecting output /mcp command, asking \"tools available?\".","code":"[mcp_servers.quartohelp] command = \"Rscript\" args = [   \"-e\",   \"ragnar::mcp_serve_store('/path/to/ragnar.store', top_k=10)\" ]"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ragnar: Retrieval-Augmented Generation (RAG) Workflows — ragnar-package","title":"ragnar: Retrieval-Augmented Generation (RAG) Workflows — ragnar-package","text":"Provides tools implementing Retrieval-Augmented Generation (RAG) workflows Large Language Models (LLM). Includes functions document processing, text chunking, embedding generation, storage management, content retrieval. Supports various document types embedding providers ('Ollama', 'OpenAI'), 'DuckDB' default storage backend. Integrates 'ellmer' package equip chat objects retrieval capabilities. Designed offer sensible defaults customization options transparent access intermediate outputs. review retrieval-augmented generation methods, see Gao et al. (2023) \"Retrieval-Augmented Generation Large Language Models: Survey\" doi:10.48550/arXiv.2312.10997 .","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ragnar: Retrieval-Augmented Generation (RAG) Workflows — ragnar-package","text":"Maintainer: Tomasz Kalinowski tomasz@posit.co Authors: Daniel Falbel daniel@posit.co contributors: Posit Software, PBC (ROR) [copyright holder, funder]","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunk.html","id":null,"dir":"Reference","previous_headings":"","what":"Chunk text — ragnar_chunk","title":"Chunk text — ragnar_chunk","text":"functions deprecated favor markdown_chunk(), flexible, supports overlapping chunks, enables deoverlapping rechunking downstream ragnar_retrieve(), automatically builds context string -scope markdown headings chunk instead requiring manual string interpolation extracted headings.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chunk text — ragnar_chunk","text":"","code":"ragnar_chunk(   x,   max_size = 1600L,   boundaries = c(\"paragraph\", \"sentence\", \"line_break\", \"word\", \"character\"),   ...,   trim = TRUE,   simplify = TRUE )  ragnar_segment(x, boundaries = \"sentence\", ..., trim = FALSE, simplify = TRUE)  ragnar_chunk_segments(x, max_size = 1600L, ..., simplify = TRUE, trim = TRUE)"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chunk text — ragnar_chunk","text":"x character vector, list character vectors, data frame containing text column. max_size Integer. maximum number characters chunk. Defaults 1600, typically approximately 400 tokens, 1 page text. boundaries sequence boundary types use order max_size satisfied. Valid values \"sentence\", \"word\", \"line_break\", \"character\", \"paragraph\", stringr_pattern object like stringr::fixed(). ... Additional arguments passed internal functions. tokenizer use tokens instead characters count (fully implemented yet) trim logical, whether trim leading trailing whitespace strings. Default TRUE. simplify Logical. TRUE, output simplified. FALSE, returns vector length x. TRUE, character strings unlist()ed, dataframes tidyr::unchop()ed.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chunk text — ragnar_chunk","text":"character input simplify = FALSE: list character vectors character input simplify = TRUE: character vector chunks data frame input simplify = FALSE: data frame number rows input, text column transformed list chararacter vectors. data frame input simplify = TRUE: data frame input simplify=FALSE, text column expanded tidyr::unchop()","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Chunk text — ragnar_chunk","text":"Functions chunking text smaller pieces preserving meaningful semantics. functions provide flexible ways split text based various boundaries (sentences, words, etc.) controlling chunk sizes overlap. Chunking combination two fundamental operations: identifying boundaries: finding character positions makes sense split string. extracting slices: extracting substrings using candidate boundaries produce chunks match requested chunk_size chunk_overlap ragnar_chunk() higher-level function , identifies boundaries extracts slices. need lower-level control, can alternatively use lower-level functions ragnar_segment() combination ragnar_chunk_segments(). ragnar_segment(): Splits text semantic boundaries. ragnar_chunk_segments(): Combines text segments chunks. usecases, two equivalent:   working data frames, functions preserve columns use tidyr::unchop() handle resulting list-columns simplify = TRUE.","code":"x |> ragnar_chunk() x |> ragnar_segment() |> ragnar_chunk_segments()"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chunk text — ragnar_chunk","text":"","code":"# Basic chunking with max size text <- \"This is a long piece of text. It has multiple sentences.          We want to split it into chunks. Here's another sentence.\" ragnar_chunk(text, max_size = 40) # splits at sentences #> [1] \"This is a long piece of text.\"    #> [2] \"It has multiple sentences.\"       #> [3] \"We want to split it into chunks.\" #> [4] \"Here's another sentence.\"          # smaller chunk size: first splits at sentence boundaries, then word boundaries ragnar_chunk(text, max_size = 20) #> [1] \"This is a long piece\" \"of text.\"             #> [3] \"It has multiple\"      \"sentences.\"           #> [5] \"We want to split it\"  \"into chunks.\"         #> [7] \"Here's another\"       \"sentence.\"             # only split at sentence boundaries. Note, some chunks are oversized ragnar_chunk(text, max_size = 20, boundaries = c(\"sentence\")) #> [1] \"This is a long piece of text.\"    #> [2] \"It has multiple sentences.\"       #> [3] \"We want to split it into chunks.\" #> [4] \"Here's another sentence.\"          # only consider word boundaries when splitting: ragnar_chunk(text, max_size = 20, boundaries = c(\"word\")) #> [1] \"This is a long piece\" \"of text. It has\"      #> [3] \"multiple sentences.\"  \"We want to\"           #> [5] \"split it into chunks\" \"s. Here's another\"    #> [7] \"sentence.\"             # first split at sentence boundaries, then word boundaries, # as needed to satisfy `max_chunk` ragnar_chunk(text, max_size = 20, boundaries = c(\"sentence\", \"word\")) #> [1] \"This is a long piece\" \"of text.\"             #> [3] \"It has multiple\"      \"sentences.\"           #> [5] \"We want to split it\"  \"into chunks.\"         #> [7] \"Here's another\"       \"sentence.\"             # Use a stringr pattern to find semantic boundaries ragnar_chunk(text, max_size = 10, boundaries = stringr::fixed(\". \")) #> [1] \"This is a long piece of text.\"                                         #> [2] \"It has multiple sentences.\\n         We want to split it into chunks.\" #> [3] \"Here's another sentence.\"                                              ragnar_chunk(text, max_size = 10, boundaries = list(stringr::fixed(\". \"), \"word\")) #>  [1] \"This is a\"  \"long piece\" \"e of text.\" \"It has\"     \"multiple\"   #>  [6] \"sentences.\" \".\"          \"We want to\" \"o split it\" \"into\"       #> [11] \"chunks.\"    \"Here's\"     \"another\"    \"sentence.\"    # Working with data frames df <- data.frame(   id = 1:2,   text = c(\"First sentence. Second sentence.\", \"Another sentence here.\") ) ragnar_chunk(df, max_size = 20, boundaries = \"sentence\") #>   id                   text #> 1  1        First sentence. #> 2  1       Second sentence. #> 3  2 Another sentence here. ragnar_chunk(df$text, max_size = 20, boundaries = \"sentence\") #> [1] \"First sentence.\"        \"Second sentence.\"       #> [3] \"Another sentence here.\"  # Chunking pre-segmented text segments <- c(\"First segment. \", \"Second segment. \", \"Third segment. \", \"Fourth segment. \") ragnar_chunk_segments(segments, max_size = 20) #> [1] \"First segment.\"  \"Second segment.\" \"Third segment.\"  #> [4] \"Fourth segment.\" ragnar_chunk_segments(segments, max_size = 40) #> [1] \"First segment. Second segment.\" \"Third segment. Fourth segment.\" ragnar_chunk_segments(segments, max_size = 60) #> [1] \"First segment. Second segment. Third segment.\" #> [2] \"Fourth segment.\""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunks_view.html","id":null,"dir":"Reference","previous_headings":"","what":"View chunks with the store inspector — ragnar_chunks_view","title":"View chunks with the store inspector — ragnar_chunks_view","text":"Visualize chunks read ragnar_read() quick inspection. Helpful inspecting results chunking reading iterating ingestion pipeline.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunks_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View chunks with the store inspector — ragnar_chunks_view","text":"","code":"ragnar_chunks_view(chunks)"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_chunks_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View chunks with the store inspector — ragnar_chunks_view","text":"chunks data frame containing chunks.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_find_links.html","id":null,"dir":"Reference","previous_headings":"","what":"Find links on a page — ragnar_find_links","title":"Find links on a page — ragnar_find_links","text":"Find links page","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_find_links.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find links on a page — ragnar_find_links","text":"","code":"ragnar_find_links(   x,   depth = 0L,   children_only = FALSE,   progress = TRUE,   ...,   url_filter = identity,   validate = FALSE )"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_find_links.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find links on a page — ragnar_find_links","text":"x URL, HTML file path, XML document. Markdown, convert HTML using commonmark::markdown_html() first. depth Integer specifying many levels deep crawl links. depth > 0, function follow child links (links x prefix) collect links pages well. children_only Logical string. TRUE, returns child links (x prefix). FALSE, returns links found page. Note regardless setting, child links followed depth > 0. progress Logical, draw progress bar depth > 0. ... Currently unused. Must empty. url_filter function takes character vector URL's may subset return smaller list. can useful filtering URL's rules different children_only checks prefix. validate Default FALSE. TRUE sends HEAD request link removes accessible. Requests sent parallel using httr2::req_perform_parallel().","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_find_links.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find links on a page — ragnar_find_links","text":"character vector links page.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_find_links.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find links on a page — ragnar_find_links","text":"","code":"# \\dontrun{ ragnar_find_links(\"https://r4ds.hadley.nz/base-R.html\") #>  [1] \"https://adv-r.hadley.nz/subsetting.html\"                         #>  [2] \"https://dplyr.tidyverse.org/reference/across.html\"               #>  [3] \"https://dplyr.tidyverse.org/reference/arrange.html\"              #>  [4] \"https://dplyr.tidyverse.org/reference/filter.html\"               #>  [5] \"https://dplyr.tidyverse.org/reference/group_by.html\"             #>  [6] \"https://dplyr.tidyverse.org/reference/mutate.html\"               #>  [7] \"https://dplyr.tidyverse.org/reference/pull.html\"                 #>  [8] \"https://dplyr.tidyverse.org/reference/relocate.html\"             #>  [9] \"https://dplyr.tidyverse.org/reference/select.html\"               #> [10] \"https://dplyr.tidyverse.org/reference/summarise.html\"            #> [11] \"https://gist.github.com/hadley/1986a273e384fb2d4d752c18ed71bedf\" #> [12] \"https://gist.github.com/hadley/c430501804349d382ce90754936ab8ec\" #> [13] \"https://github.com/hadley/r4ds\"                                  #> [14] \"https://github.com/hadley/r4ds/edit/main/base-R.qmd\"             #> [15] \"https://github.com/hadley/r4ds/issues/new\"                       #> [16] \"https://purrr.tidyverse.org/reference/map.html\"                  #> [17] \"https://quarto.org\"                                              #> [18] \"https://r4ds.hadley.nz/EDA.html\"                                 #> [19] \"https://r4ds.hadley.nz/arrow.html\"                               #> [20] \"https://r4ds.hadley.nz/base-R.html\"                              #> [21] \"https://r4ds.hadley.nz/communicate.html\"                         #> [22] \"https://r4ds.hadley.nz/communication.html\"                       #> [23] \"https://r4ds.hadley.nz/data-import.html\"                         #> [24] \"https://r4ds.hadley.nz/data-tidy.html\"                           #> [25] \"https://r4ds.hadley.nz/data-transform.html\"                      #> [26] \"https://r4ds.hadley.nz/data-visualize.html\"                      #> [27] \"https://r4ds.hadley.nz/databases.html\"                           #> [28] \"https://r4ds.hadley.nz/datetimes.html\"                           #> [29] \"https://r4ds.hadley.nz/factors.html\"                             #> [30] \"https://r4ds.hadley.nz/functions.html\"                           #> [31] \"https://r4ds.hadley.nz/import.html\"                              #> [32] \"https://r4ds.hadley.nz/intro.html\"                               #> [33] \"https://r4ds.hadley.nz/iteration.html\"                           #> [34] \"https://r4ds.hadley.nz/joins.html\"                               #> [35] \"https://r4ds.hadley.nz/layers.html\"                              #> [36] \"https://r4ds.hadley.nz/logicals.html\"                            #> [37] \"https://r4ds.hadley.nz/missing-values.html\"                      #> [38] \"https://r4ds.hadley.nz/numbers.html\"                             #> [39] \"https://r4ds.hadley.nz/preface-2e.html\"                          #> [40] \"https://r4ds.hadley.nz/program.html\"                             #> [41] \"https://r4ds.hadley.nz/quarto-formats.html\"                      #> [42] \"https://r4ds.hadley.nz/quarto.html\"                              #> [43] \"https://r4ds.hadley.nz/rectangling.html\"                         #> [44] \"https://r4ds.hadley.nz/regexps.html\"                             #> [45] \"https://r4ds.hadley.nz/spreadsheets.html\"                        #> [46] \"https://r4ds.hadley.nz/strings.html\"                             #> [47] \"https://r4ds.hadley.nz/transform.html\"                           #> [48] \"https://r4ds.hadley.nz/visualize.html\"                           #> [49] \"https://r4ds.hadley.nz/webscraping.html\"                         #> [50] \"https://r4ds.hadley.nz/whole-game.html\"                          #> [51] \"https://r4ds.hadley.nz/workflow-basics.html\"                     #> [52] \"https://r4ds.hadley.nz/workflow-help.html\"                       #> [53] \"https://r4ds.hadley.nz/workflow-scripts.html\"                    #> [54] \"https://r4ds.hadley.nz/workflow-style.html\"                      #> [55] \"https://rdrr.io/r/base/Arithmetic.html\"                          #> [56] \"https://rdrr.io/r/base/Extremes.html\"                            #> [57] \"https://rdrr.io/r/base/NA.html\"                                  #> [58] \"https://rdrr.io/r/base/apply.html\"                               #> [59] \"https://rdrr.io/r/base/c.html\"                                   #> [60] \"https://rdrr.io/r/base/cbind.html\"                               #> [61] \"https://rdrr.io/r/base/data.frame.html\"                          #> [62] \"https://rdrr.io/r/base/do.call.html\"                             #> [63] \"https://rdrr.io/r/base/lapply.html\"                              #> [64] \"https://rdrr.io/r/base/length.html\"                              #> [65] \"https://rdrr.io/r/base/levels.html\"                              #> [66] \"https://rdrr.io/r/base/library.html\"                             #> [67] \"https://rdrr.io/r/base/list.files.html\"                          #> [68] \"https://rdrr.io/r/base/list.html\"                                #> [69] \"https://rdrr.io/r/base/logical.html\"                             #> [70] \"https://rdrr.io/r/base/mean.html\"                                #> [71] \"https://rdrr.io/r/base/numeric.html\"                             #> [72] \"https://rdrr.io/r/base/order.html\"                               #> [73] \"https://rdrr.io/r/base/seq.html\"                                 #> [74] \"https://rdrr.io/r/base/subset.html\"                              #> [75] \"https://rdrr.io/r/base/sum.html\"                                 #> [76] \"https://rdrr.io/r/base/tapply.html\"                              #> [77] \"https://rdrr.io/r/base/transform.html\"                           #> [78] \"https://rdrr.io/r/base/vector.html\"                              #> [79] \"https://rdrr.io/r/base/which.html\"                               #> [80] \"https://rdrr.io/r/base/with.html\"                                #> [81] \"https://rdrr.io/r/graphics/hist.html\"                            #> [82] \"https://rdrr.io/r/graphics/plot.default.html\"                    #> [83] \"https://rdrr.io/r/stats/Uniform.html\"                            #> [84] \"https://rdrr.io/r/utils/str.html\"                                #> [85] \"https://readxl.tidyverse.org/reference/read_excel.html\"          #> [86] \"https://tibble.tidyverse.org/reference/tibble.html\"              #> [87] \"https://tidyselect.r-lib.org/reference/starts_with.html\"         #> [88] \"https://tidyverse.tidyverse.org\"                                 ragnar_find_links(\"https://ellmer.tidyverse.org/\") #>  [1] \"http://schloerke.com\"                                                                                   #>  [2] \"https://ai.google.dev/gemini-api/terms\"                                                                 #>  [3] \"https://cloud.r-project.org/package=ellmer\"                                                             #>  [4] \"https://docs.posit.co/connect/user/oauth-integrations\"                                                  #>  [5] \"https://docs.posit.co/ide/server-pro/user/posit-workbench/managed-credentials/managed-credentials.html\" #>  [6] \"https://ellmer.tidyverse.org\"                                                                           #>  [7] \"https://ellmer.tidyverse.org/LICENSE-text.html\"                                                         #>  [8] \"https://ellmer.tidyverse.org/LICENSE.html\"                                                              #>  [9] \"https://ellmer.tidyverse.org/articles/ellmer.html\"                                                      #> [10] \"https://ellmer.tidyverse.org/articles/programming.html\"                                                 #> [11] \"https://ellmer.tidyverse.org/articles/prompt-design.html\"                                               #> [12] \"https://ellmer.tidyverse.org/articles/streaming-async.html\"                                             #> [13] \"https://ellmer.tidyverse.org/articles/structured-data.html\"                                             #> [14] \"https://ellmer.tidyverse.org/articles/tool-calling.html\"                                                #> [15] \"https://ellmer.tidyverse.org/authors.html\"                                                              #> [16] \"https://ellmer.tidyverse.org/index.html\"                                                                #> [17] \"https://ellmer.tidyverse.org/news/index.html\"                                                           #> [18] \"https://ellmer.tidyverse.org/reference/chat-any.html\"                                                   #> [19] \"https://ellmer.tidyverse.org/reference/chat_anthropic.html\"                                             #> [20] \"https://ellmer.tidyverse.org/reference/chat_aws_bedrock.html\"                                           #> [21] \"https://ellmer.tidyverse.org/reference/chat_azure_openai.html\"                                          #> [22] \"https://ellmer.tidyverse.org/reference/chat_cloudflare.html\"                                            #> [23] \"https://ellmer.tidyverse.org/reference/chat_cortex_analyst.html\"                                        #> [24] \"https://ellmer.tidyverse.org/reference/chat_databricks.html\"                                            #> [25] \"https://ellmer.tidyverse.org/reference/chat_deepseek.html\"                                              #> [26] \"https://ellmer.tidyverse.org/reference/chat_github.html\"                                                #> [27] \"https://ellmer.tidyverse.org/reference/chat_google_gemini.html\"                                         #> [28] \"https://ellmer.tidyverse.org/reference/chat_groq.html\"                                                  #> [29] \"https://ellmer.tidyverse.org/reference/chat_huggingface.html\"                                           #> [30] \"https://ellmer.tidyverse.org/reference/chat_mistral.html\"                                               #> [31] \"https://ellmer.tidyverse.org/reference/chat_ollama.html\"                                                #> [32] \"https://ellmer.tidyverse.org/reference/chat_openai.html\"                                                #> [33] \"https://ellmer.tidyverse.org/reference/chat_openrouter.html\"                                            #> [34] \"https://ellmer.tidyverse.org/reference/chat_perplexity.html\"                                            #> [35] \"https://ellmer.tidyverse.org/reference/chat_snowflake.html\"                                             #> [36] \"https://ellmer.tidyverse.org/reference/chat_vllm.html\"                                                  #> [37] \"https://ellmer.tidyverse.org/reference/content_image_url.html\"                                          #> [38] \"https://ellmer.tidyverse.org/reference/index.html\"                                                      #> [39] \"https://ellmer.tidyverse.org/reference/live_console.html\"                                               #> [40] \"https://garrickadenbuie.com\"                                                                            #> [41] \"https://github.com/posit-dev/chatlas\"                                                                   #> [42] \"https://github.com/tidyverse/ellmer\"                                                                    #> [43] \"https://github.com/tidyverse/ellmer/issues\"                                                             #> [44] \"https://hadley.nz\"                                                                                      #> [45] \"https://ollama.com\"                                                                                     #> [46] \"https://opensource.org/licenses/mit-license.php\"                                                        #> [47] \"https://orcid.org/0000-0001-9986-114X\"                                                                  #> [48] \"https://orcid.org/0000-0002-7111-0077\"                                                                  #> [49] \"https://orcid.org/0000-0003-4757-117X\"                                                                  #> [50] \"https://pkgdown.r-lib.org\"                                                                              #> [51] \"https://posit-dev.github.io/mcptools\"                                                                   #> [52] \"https://posit-dev.github.io/shinychat\"                                                                  #> [53] \"https://posit.co/blog/announcing-ellmer\"                                                                #> [54] \"https://r6.r-lib.org\"                                                                                   #> [55] \"https://ragnar.tidyverse.org\"                                                                           #> [56] \"https://rdrr.io/r/base/library.html\"                                                                    #> [57] \"https://rdrr.io/r/utils/install.packages.html\"                                                          #> [58] \"https://rdrr.io/r/utils/str.html\"                                                                       #> [59] \"https://ror.org/03wc8by49\"                                                                              #> [60] \"https://vitals.tidyverse.org\"                                                                           #> [61] \"https://www.posit.co\"                                                                                   #> [62] \"https://www.tidyverse.org/blog/2025/05/ellmer-0-2-0\"                                                    #> [63] \"https://www.tidyverse.org/blog/2025/07/ellmer-0-3-0\"                                                    ragnar_find_links(   paste0(\"https://github.com/Snowflake-Labs/sfquickstarts/\",          \"tree/master/site/sfguides/src/build_a_custom_model_for_anomaly_detection\"),   children_only = \"https://github.com/Snowflake-Labs/sfquickstarts\",   depth = 1 ) #> ⠙ Finding links: 4 | On queue: 3 | Current depth: 1 | [5s] #> ⠹ Finding links: 8 | On queue: 0 | Current depth: 1 | [7s] #>   [1] \"https://github.com/Snowflake-Labs/sfquickstarts\"                                                                           #>   [2] \"https://github.com/Snowflake-Labs/sfquickstarts/actions\"                                                                   #>   [3] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/caches\"                                                            #>   [4] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/runs/18788363058\"                                                  #>   [5] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/runs/18788363058/workflow\"                                         #>   [6] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/runs/18788729669\"                                                  #>   [7] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/runs/18788729669/workflow\"                                         #>   [8] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/runs/18790526152\"                                                  #>   [9] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/runs/18790526152/workflow\"                                         #>  [10] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/runs/18790943610\"                                                  #>  [11] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/runs/18790943610/workflow\"                                         #>  [12] \"https://github.com/Snowflake-Labs/sfquickstarts/actions/workflows/validate-and-stage.yml\"                                  #>  [13] \"https://github.com/Snowflake-Labs/sfquickstarts/activity\"                                                                  #>  [14] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/.Rhistory\"                                                     #>  [15] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/.gitignore\"                                                    #>  [16] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/.nvmrc\"                                                        #>  [17] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/.travis.yml\"                                                   #>  [18] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/BUILD.bazel\"                                                   #>  [19] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/FORMAT-GUIDE.md\"                                               #>  [20] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/LEGAL.md\"                                                      #>  [21] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/LICENSE\"                                                       #>  [22] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/MODULE.bazel\"                                                  #>  [23] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/MODULE.bazel.lock\"                                             #>  [24] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/README.md\"                                                     #>  [25] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/SECURITY.md\"                                                   #>  [26] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/WORKSPACE\"                                                     #>  [27] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/package.json\"                                                  #>  [28] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/sfquickstarts.Rproj\"                                           #>  [29] \"https://github.com/Snowflake-Labs/sfquickstarts/blob/master/site/app/styles/_overrides.scss\"                               #>  [30] \"https://github.com/Snowflake-Labs/sfquickstarts/branches\"                                                                  #>  [31] \"https://github.com/Snowflake-Labs/sfquickstarts/commits/master\"                                                            #>  [32] \"https://github.com/Snowflake-Labs/sfquickstarts/community\"                                                                 #>  [33] \"https://github.com/Snowflake-Labs/sfquickstarts/compare\"                                                                   #>  [34] \"https://github.com/Snowflake-Labs/sfquickstarts/custom-properties\"                                                         #>  [35] \"https://github.com/Snowflake-Labs/sfquickstarts/deployments\"                                                               #>  [36] \"https://github.com/Snowflake-Labs/sfquickstarts/forks\"                                                                     #>  [37] \"https://github.com/Snowflake-Labs/sfquickstarts/graphs/code-frequency\"                                                     #>  [38] \"https://github.com/Snowflake-Labs/sfquickstarts/graphs/commit-activity\"                                                    #>  [39] \"https://github.com/Snowflake-Labs/sfquickstarts/graphs/contributors\"                                                       #>  [40] \"https://github.com/Snowflake-Labs/sfquickstarts/issues\"                                                                    #>  [41] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2401\"                                                               #>  [42] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2402\"                                                               #>  [43] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2404\"                                                               #>  [44] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2409\"                                                               #>  [45] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2422\"                                                               #>  [46] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2430/linked_closing_reference?reference_location=REPO_ISSUES_INDEX\" #>  [47] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2437\"                                                               #>  [48] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2448\"                                                               #>  [49] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2449\"                                                               #>  [50] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2466\"                                                               #>  [51] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2471\"                                                               #>  [52] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2473\"                                                               #>  [53] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/2481\"                                                               #>  [54] \"https://github.com/Snowflake-Labs/sfquickstarts/issues/new/choose\"                                                         #>  [55] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3AKevols\"                      #>  [56] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3AShilpV\"                      #>  [57] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Acmareco\"                     #>  [58] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Aharrison-burchfield\"         #>  [59] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Asauravcal\"                   #>  [60] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Asfc-gh-anowlan\"              #>  [61] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Asfc-gh-dchaffelson\"          #>  [62] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Asfc-gh-mpenumathsa\"          #>  [63] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Asfc-gh-sweingartner\"         #>  [64] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Asfc-gh-wzou\"                 #>  [65] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Aissue%20state%3Aopen%20author%3Asimakowskiw\"                 #>  [66] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3AEveerasingam\"                          #>  [67] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3AG-r-ay\"                                #>  [68] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Aadieado\"                               #>  [69] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Aannettechen\"                           #>  [70] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Acorydonbaylor\"                         #>  [71] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Adgnestsn\"                              #>  [72] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Afjaguero\"                              #>  [73] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Ajamescha-earley\"                       #>  [74] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Ajunkai-roe-ai\"                         #>  [75] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Akanwalzs\"                              #>  [76] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Amando222\"                              #>  [77] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Aquintonwall\"                           #>  [78] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-apaniaguaguerrero\"              #>  [79] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-chammond\"                       #>  [80] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-etolotti\"                       #>  [81] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-hgallagher\"                     #>  [82] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-jreini\"                         #>  [83] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-knjeru\"                         #>  [84] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-mfus\"                           #>  [85] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-mnixon\"                         #>  [86] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Asfc-gh-twhite\"                         #>  [87] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Ashamernick1\"                           #>  [88] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Avinodhini-sd\"                          #>  [89] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+author%3Azhengchaoyan\"                          #>  [90] \"https://github.com/Snowflake-Labs/sfquickstarts/issues?q=is%3Apr+is%3Aopen+no%3Amilestone\"                                 #>  [91] \"https://github.com/Snowflake-Labs/sfquickstarts/labels\"                                                                    #>  [92] \"https://github.com/Snowflake-Labs/sfquickstarts/milestones\"                                                                #>  [93] \"https://github.com/Snowflake-Labs/sfquickstarts/network\"                                                                   #>  [94] \"https://github.com/Snowflake-Labs/sfquickstarts/network/dependencies\"                                                      #>  [95] \"https://github.com/Snowflake-Labs/sfquickstarts/projects?is_search=true&query=is%3Aclosed\"                                 #>  [96] \"https://github.com/Snowflake-Labs/sfquickstarts/projects?is_search=true&query=is%3Aopen\"                                   #>  [97] \"https://github.com/Snowflake-Labs/sfquickstarts/projects?query=is%3Aopen\"                                                  #>  [98] \"https://github.com/Snowflake-Labs/sfquickstarts/projects?query=is%3Aopen+is%3Atemplate\"                                    #>  [99] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/1867\"                                                                 #> [100] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/1870\"                                                                 #> [101] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/1900\"                                                                 #> [102] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/1910\"                                                                 #> [103] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/1948\"                                                                 #> [104] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/1992\"                                                                 #> [105] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2012\"                                                                 #> [106] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2057\"                                                                 #> [107] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2079\"                                                                 #> [108] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2098\"                                                                 #> [109] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2115\"                                                                 #> [110] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2116\"                                                                 #> [111] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2145\"                                                                 #> [112] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2172\"                                                                 #> [113] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2196\"                                                                 #> [114] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2223\"                                                                 #> [115] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2272\"                                                                 #> [116] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2273\"                                                                 #> [117] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2281\"                                                                 #> [118] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2428\"                                                                 #> [119] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2430\"                                                                 #> [120] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2477\"                                                                 #> [121] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2479\"                                                                 #> [122] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2480\"                                                                 #> [123] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2491\"                                                                 #> [124] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2492\"                                                                 #> [125] \"https://github.com/Snowflake-Labs/sfquickstarts/pull/2493\"                                                                 #> [126] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls\"                                                                     #> [127] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?page=2&q=is%3Apr+is%3Aopen\"                                          #> [128] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?page=3&q=is%3Apr+is%3Aopen\"                                          #> [129] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?page=4&q=is%3Apr+is%3Aopen\"                                          #> [130] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Aopen+is%3Apr\"                                                 #> [131] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aclosed\"                                               #> [132] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+no%3Aassignee\"                                   #> [133] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+review%3Aapproved\"                               #> [134] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+review%3Achanges-requested\"                      #> [135] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+review%3Anone\"                                   #> [136] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+review%3Arequired\"                               #> [137] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Acomments-asc\"                             #> [138] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Acomments-desc\"                            #> [139] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Acreated-asc\"                              #> [140] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Areactions-%2B1-desc\"                      #> [141] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Areactions--1-desc\"                        #> [142] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Areactions-eyes-desc\"                      #> [143] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Areactions-heart-desc\"                     #> [144] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Areactions-rocket-desc\"                    #> [145] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Areactions-smile-desc\"                     #> [146] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Areactions-tada-desc\"                      #> [147] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Areactions-thinking_face-desc\"             #> [148] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Arelevance-desc\"                           #> [149] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Aupdated-asc\"                              #> [150] \"https://github.com/Snowflake-Labs/sfquickstarts/pulls?q=is%3Apr+is%3Aopen+sort%3Aupdated-desc\"                             #> [151] \"https://github.com/Snowflake-Labs/sfquickstarts/pulse\"                                                                     #> [152] \"https://github.com/Snowflake-Labs/sfquickstarts/search?l=go\"                                                               #> [153] \"https://github.com/Snowflake-Labs/sfquickstarts/search?l=html\"                                                             #> [154] \"https://github.com/Snowflake-Labs/sfquickstarts/search?l=javascript\"                                                       #> [155] \"https://github.com/Snowflake-Labs/sfquickstarts/search?l=jupyter-notebook\"                                                 #> [156] \"https://github.com/Snowflake-Labs/sfquickstarts/search?l=python\"                                                           #> [157] \"https://github.com/Snowflake-Labs/sfquickstarts/search?l=scss\"                                                             #> [158] \"https://github.com/Snowflake-Labs/sfquickstarts/security\"                                                                  #> [159] \"https://github.com/Snowflake-Labs/sfquickstarts/stargazers\"                                                                #> [160] \"https://github.com/Snowflake-Labs/sfquickstarts/tags\"                                                                      #> [161] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/master/.github/ISSUE_TEMPLATE\"                                        #> [162] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/master/.vscode\"                                                       #> [163] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/master/claat\"                                                         #> [164] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/master/codelab-elements\"                                              #> [165] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/master/site\"                                                          #> [166] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/master/third_party\"                                                   #> [167] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/master/tmp/your-first-pwapp\"                                          #> [168] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/refs/heads/test/test-new-workflow-1\"                                  #> [169] \"https://github.com/Snowflake-Labs/sfquickstarts/tree/refs/heads/test/test-new-workflow-2\"                                  #> [170] \"https://github.com/Snowflake-Labs/sfquickstarts/watchers\"                                                                  # }"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a document as Markdown — ragnar_read","title":"Read a document as Markdown — ragnar_read","text":"function deprecated favor read_as_markdown().","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a document as Markdown — ragnar_read","text":"","code":"ragnar_read(x, ..., split_by_tags = NULL, frame_by_tags = NULL)"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a document as Markdown — ragnar_read","text":"x file path url. ... passed markitdown.convert. split_by_tags character vector html tag names used split returned text frame_by_tags character vector html tag names used create dataframe returned content","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a document as Markdown — ragnar_read","text":"Always returns data frame columns: origin: file path url hash: hash text content text: markdown content split_by_tags NULL, tag column also included containing corresponding tag text chunk. \"\" used text chunks associated tag. frame_by_tags NULL, additional columns included tag frame_by_tags. text chunks associated tags order appear markdown content.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read a document as Markdown — ragnar_read","text":"ragnar_read() uses markitdown convert document markdown. frame_by_tags split_by_tags provided, converted markdown content split converted data frame, otherwise, markdown returned string.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a document as Markdown — ragnar_read","text":"","code":"file <- tempfile(fileext = \".html\") download.file(\"https://r4ds.hadley.nz/base-R.html\", file, quiet = TRUE)  # with no arguments, returns a single row data frame. # the markdown content is in the `text` column. file |> ragnar_read() |> str() #> tibble [1 × 3] (S3: tbl_df/tbl/data.frame) #>  $ origin: chr \"/tmp/Rtmpw5SQQS/file1f946704fd6d.html\" #>  $ hash  : chr \"2ee102437af8ad1f0d7382739357e490\" #>  $ text  : <ragnar::MarkdownDocument> chr \"# 27  A field guide to base R – R for Data Science (2e)\\n\\n# 27  A field guide to base R\\n\\n## 27.1 Introductio\"| __truncated__ #>   ..@ origin: chr \"/tmp/Rtmpw5SQQS/file1f946704fd6d.html\"  # use `split_by_tags` to get a data frame where the text is split by the # specified tags (e.g., \"h1\", \"h2\", \"h3\") file |>   ragnar_read(split_by_tags = c(\"h1\", \"h2\", \"h3\")) #> # A tibble: 34 × 4 #>    origin                                hash               tag   text  #>    <chr>                                 <chr>              <chr> <chr> #>  1 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"h1\"  \"# 2… #>  2 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"h1\"  \"# 2… #>  3 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"h2\"  \"## … #>  4 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"\"    \"To … #>  5 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"h3\"  \"###… #>  6 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"\"    \"Thi… #>  7 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"h2\"  \"## … #>  8 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"\"    \"`[`… #>  9 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"h3\"  \"###… #> 10 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee102437af8ad1f0… \"\"    \"The… #> # ℹ 24 more rows  # use `frame_by_tags` to get a dataframe where the # headings associated with each text chunk are easily accessible file |>   ragnar_read(frame_by_tags = c(\"h1\", \"h2\", \"h3\")) #> # A tibble: 17 × 6 #>    origin                                hash   h1    h2    h3    text  #>    <chr>                                 <chr>  <chr> <chr> <chr> <chr> #>  1 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… NA    NA     NA   #>  2 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… NA    \"To … #>  3 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"Thi… #>  4 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… NA    \"`[`… #>  5 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"The… #>  6 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"The… #>  7 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"Sev… #>  8 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"1. … #>  9 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… NA    \"`[`… #> 10 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"`[[… #> 11 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"The… #> 12 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"`[[… #> 13 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… ### … \"1. … #> 14 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… NA    \"In … #> 15 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… NA    \"`fo… #> 16 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… NA    \"Man… #> 17 /tmp/Rtmpw5SQQS/file1f946704fd6d.html 2ee10… # 27… ## 2… NA    \"In …  # use `split_by_tags` and `frame_by_tags` together to further break up `text`. file |>   ragnar_read(     split_by_tags = c(\"p\"),     frame_by_tags = c(\"h1\", \"h2\", \"h3\")   ) #> # A tibble: 120 × 7 #>    origin                           hash  h1    h2    h3    tag   text  #>    <chr>                            <chr> <chr> <chr> <chr> <chr> <chr> #>  1 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… NA    NA     NA    NA   #>  2 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… NA    \"p\"   \"To … #>  3 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… NA    \"p\"   \"Thi… #>  4 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… NA    \"p\"   \"Aft… #>  5 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… NA    \"p\"   \"In … #>  6 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… ### … \"p\"   \"Thi… #>  7 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… ### … \"\"    \"```… #>  8 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… NA    \"p\"   \"`[`… #>  9 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… ### … \"p\"   \"The… #> 10 /tmp/Rtmpw5SQQS/file1f946704fd6… 2ee1… # 27… ## 2… ### … \"\"    \"1.\"  #> # ℹ 110 more rows  # Example workflow adding context to each chunk file |>   ragnar_read(frame_by_tags = c(\"h1\", \"h2\", \"h3\")) |>   glue::glue_data(r\"--(     ## Excerpt from the book \"R for Data Science (2e)\"     chapter: {h1}     section: {h2}     content: {text}      )--\") |>   # inspect   _[6:7] |> cat(sep = \"\\n~~~~~~~~~~~\\n\") #> ## Excerpt from the book \"R for Data Science (2e)\" #> chapter: # 27  A field guide to base R #> section: ## 27.2 Selecting multiple elements with `[` #> content: There are quite a few different ways[1](#fn1) that you can use `[` with a data frame, but the most important way is to select rows and columns independently with `df[rows, cols]`. Here `rows` and `cols` are vectors as described above. For example, `df[rows, ]` and `df[, cols]` select just rows or just columns, using the empty subset to preserve the other dimension. #>  #> Here are a couple of examples: #>  #> ```r #> df <- tibble( #>   x = 1:3, #>   y = c(\"a\", \"e\", \"f\"), #>   z = runif(3) #> ) #>  #> # Select first row and second column #> df[1, 2] #> #> # A tibble: 1 × 1 #> #>   y #> #>   <chr> #> #> 1 a #>  #> # Select all rows and columns x and y #> df[, c(\"x\" , \"y\")] #> #> # A tibble: 3 × 2 #> #>       x y #> #>   <int> <chr> #> #> 1     1 a #> #> 2     2 e #> #> 3     3 f #>  #> # Select rows where `x` is greater than 1 and all columns #> df[df$x > 1, ] #> #> # A tibble: 2 × 3 #> #>       x y         z #> #>   <int> <chr> <dbl> #> #> 1     2 e     0.834 #> #> 2     3 f     0.601 #> ``` #>  #> We’ll come back to `$` shortly, but you should be able to guess what `df$x` does from the context: it extracts the `x` variable from `df`. We need to use it here because `[` doesn’t use tidy evaluation, so you need to be explicit about the source of the `x` variable. #>  #> There’s an important difference between tibbles and data frames when it comes to `[`. In this book, we’ve mainly used tibbles, which *are* data frames, but they tweak some behaviors to make your life a little easier. In most places, you can use “tibble” and “data frame” interchangeably, so when we want to draw particular attention to R’s built-in data frame, we’ll write `data.frame`. If `df` is a `data.frame`, then `df[, cols]` will return a vector if `col` selects a single column and a data frame if it selects more than one column. If `df` is a tibble, then `[` will always return a tibble. #>  #> ```r #> df1 <- data.frame(x = 1:3) #> df1[, \"x\"] #> #> [1] 1 2 3 #>  #> df2 <- tibble(x = 1:3) #> df2[, \"x\"] #> #> # A tibble: 3 × 1 #> #>       x #> #>   <int> #> #> 1     1 #> #> 2     2 #> #> 3     3 #> ``` #>  #> One way to avoid this ambiguity with `data.frame`s is to explicitly specify `drop = FALSE`: #>  #> ```r #> df1[, \"x\" , drop = FALSE] #> #>   x #> #> 1 1 #> #> 2 2 #> #> 3 3 #> ``` #>  #> ~~~~~~~~~~~ #> ## Excerpt from the book \"R for Data Science (2e)\" #> chapter: # 27  A field guide to base R #> section: ## 27.2 Selecting multiple elements with `[` #> content: Several dplyr verbs are special cases of `[`: #>  #> * `[filter()](https://dplyr.tidyverse.org/reference/filter.html)` is equivalent to subsetting the rows with a logical vector, taking care to exclude missing values: #>  #>   ```r #>   df <- tibble( #>     x = c(2, 3, 1, 1, NA), #>     y = letters[1:5], #>     z = runif(5) #>   ) #>   df |> filter(x > 1) #>  #>   # same as #>   df[!is.na(df$x) & df$x > 1, ] #>   ``` #>  #>   Another common technique in the wild is to use `[which()](https://rdrr.io/r/base/which.html)` for its side-effect of dropping missing values: `df[which(df$x > 1), ]`. #> * `[arrange()](https://dplyr.tidyverse.org/reference/arrange.html)` is equivalent to subsetting the rows with an integer vector, usually created with `[order()](https://rdrr.io/r/base/order.html)`: #>  #>   ```r #>   df |> arrange(x, y) #>  #>   # same as #>   df[order(df$x, df$y), ] #>   ``` #>  #>   You can use `order(decreasing = TRUE)` to sort all columns in descending order or `-rank(col)` to sort columns in decreasing order individually. #> * Both `[select()](https://dplyr.tidyverse.org/reference/select.html)` and `[relocate()](https://dplyr.tidyverse.org/reference/relocate.html)` are similar to subsetting the columns with a character vector: #>  #>   ```r #>   df |> select(x, z) #>  #>   # same as #>   df[, c(\"x\", \"z\")] #>   ``` #>  #> Base R also provides a function that combines the features of `[filter()](https://dplyr.tidyverse.org/reference/filter.html)` and `[select()](https://dplyr.tidyverse.org/reference/select.html)`[2](#fn2) called `[subset()](https://rdrr.io/r/base/subset.html)`: #>  #> ```r #> df |> #>   filter(x > 1) |> #>   select(y, z) #> #> # A tibble: 2 × 2 #> #>   y           z #> #>   <chr>   <dbl> #> #> 1 a     0.157 #> #> 2 b     0.00740 #> ``` #>  #> ```r #> # same as #> df |> subset(x > 1, c(y, z)) #> ``` #>  #> This function was the inspiration for much of dplyr’s syntax. #>   # Advanced example of postprocessing the output of ragnar_read() # to add language to code blocks, markdown style library(dplyr, warn.conflicts = FALSE) library(stringr) library(rvest) library(xml2) file |>   ragnar_read(frame_by_tags = c(\"h1\", \"h2\", \"h3\"),               split_by_tags = c(\"p\", \"pre\")) |>   mutate(     is_code = tag == \"pre\",     text = ifelse(is_code, str_replace(text, \"```\", \"```r\"), text)   ) |>   group_by(h1, h2, h3) |>   summarise(text = str_flatten(text, \"\\n\\n\"), .groups = \"drop\") |>   glue::glue_data(r\"--(     # Excerpt from the book \"R for Data Science (2e)\"     chapter: {h1}     section: {h2}     content: {text}      )--\") |>   # inspect   _[9:10] |> cat(sep = \"\\n~~~~~~~~~~~\\n\") #> # Excerpt from the book \"R for Data Science (2e)\" #> chapter: # 27  A field guide to base R #> section: ## 27.3 Selecting a single element with `$` and `[[` #> content: There are a couple of important differences between tibbles and base `data.frame`s when it comes to `$`. Data frames match the prefix of any variable names (so-called **partial matching**) and don’t complain if a column doesn’t exist: #>  #> ```rr #> df <- data.frame(x1 = 1) #> df$x #> #> [1] 1 #> df$z #> #> NULL #> ``` #>  #> Tibbles are more strict: they only ever match variable names exactly and they will generate a warning if the column you are trying to access doesn’t exist: #>  #> ```rr #> tb <- tibble(x1 = 1) #>  #> tb$x #> #> Warning: Unknown or uninitialised column: `x`. #> #> NULL #> tb$z #> #> Warning: Unknown or uninitialised column: `z`. #> #> NULL #> ``` #>  #> For this reason we sometimes joke that tibbles are lazy and surly: they do less and complain more. #>  #> ~~~~~~~~~~~ #> # Excerpt from the book \"R for Data Science (2e)\" #> chapter: # 27  A field guide to base R #> section: ## 27.3 Selecting a single element with `$` and `[[` #> content: `[[` and `$` are also really important for working with lists, and it’s important to understand how they differ from `[`. Let’s illustrate the differences with a list named `l`: #>  #> ```rr #> l <- list( #>   a = 1:3, #>   b = \"a string\", #>   c = pi, #>   d = list(-1, -5) #> ) #> ``` #>  #> * #>  #> `[` extracts a sub-list. It doesn’t matter how many elements you extract, the result will always be a list. #>  #> ```rr #>   str(l[1:2]) #>   #> List of 2 #>   #>  $ a: int [1:3] 1 2 3 #>   #>  $ b: chr \"a string\" #>  #>   str(l[1]) #>   #> List of 1 #>   #>  $ a: int [1:3] 1 2 3 #>  #>   str(l[4]) #>   #> List of 1 #>   #>  $ d:List of 2 #>   #>   ..$ : num -1 #>   #>   ..$ : num -5 #>   ``` #>  #> Like with vectors, you can subset with a logical, integer, or character vector. #>  #> * #>  #> `[[` and `$` extract a single component from a list. They remove a level of hierarchy from the list. #>  #> ```rr #>   str(l[[1]]) #>   #>  int [1:3] 1 2 3 #>  #>   str(l[[4]]) #>   #> List of 2 #>   #>  $ : num -1 #>   #>  $ : num -5 #>  #>   str(l$a) #>   #>  int [1:3] 1 2 3 #>   ``` #>  #> The difference between `[` and `[[` is particularly important for lists because `[[` drills down into the list while `[` returns a new, smaller list. To help you remember the difference, take a look at the unusual pepper shaker shown in [Figure 27.1](#fig-pepper). If this pepper shaker is your list `pepper`, then, `pepper[1]` is a pepper shaker containing a single pepper packet. `pepper[2]` would look the same, but would contain the second packet. `pepper[1:2]` would be a pepper shaker containing two pepper packets. `pepper[[1]]` would extract the pepper packet itself. #>  #> ![Three photos. On the left is a photo of a glass pepper shaker. Instead of  the pepper shaker containing pepper, it contains a single packet of pepper. In the middle is a photo of a single packet of pepper. On the right is a  photo of the contents of a packet of pepper.](diagrams/pepper.png) #>  #> Figure 27.1: (Left) A pepper shaker that Hadley once found in his hotel room. (Middle) `pepper[1]`. (Right) `pepper[[1]]` #>  #> This same principle applies when you use 1d `[` with a data frame: `df[\"x\"]` returns a one-column data frame and `df[[\"x\"]]` returns a vector. #>"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read_document.html","id":null,"dir":"Reference","previous_headings":"","what":"Read an HTML document — ragnar_read_document","title":"Read an HTML document — ragnar_read_document","text":"Read HTML document","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read_document.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read an HTML document — ragnar_read_document","text":"","code":"ragnar_read_document(   x,   ...,   split_by_tags = frame_by_tags,   frame_by_tags = NULL )"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read_document.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read an HTML document — ragnar_read_document","text":"x file path url, passed rvest::read_html(), xml_node. ... passed rvest::read_html() split_by_tags character vector html tag names used split returned text frame_by_tags character vector html tag names used create dataframe returned content","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read_document.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read an HTML document — ragnar_read_document","text":"frame_by_tags NULL, data frame returned, column names c(\"frame_by_tags\", \"text\"). frame_by_tags NULL split_by_tags NULL, named character vector returned. frame_by_tags split_by_tags NULL, string (length-1 character vector) returned.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_read_document.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read an HTML document — ragnar_read_document","text":"","code":"file <- tempfile(fileext = \".html\") download.file(\"https://r4ds.hadley.nz/base-R.html\", file, quiet = TRUE)  # with no arguments, returns a single string of the text. file |> ragnar_read_document() |> str() #>  chr \"Program\\n27 A field guide to base R\\nR for Data Science (2e)\\nWelcome\\nPreface to the second edition\\nIntroduct\"| __truncated__  # use `split_by_tags` to get a named character vector of length > 1 file |>   ragnar_read_document(split_by_tags = c(\"h1\", \"h2\", \"h3\")) |>   tibble::enframe(\"tag\", \"text\") #> # A tibble: 36 × 2 #>    tag   text                                                           #>    <chr> <chr>                                                          #>  1 \"\"    \"Program\\n27 A field guide to base R\\nR for Data Science (2e)… #>  2 \"h2\"  \"Table of contents\"                                            #>  3 \"\"    \"27.1 Introduction\\n27.1.1 Prerequisites\\n27.2 Selecting mult… #>  4 \"h1\"  \"27 A field guide to base R\"                                   #>  5 \"h2\"  \"27.1 Introduction\"                                            #>  6 \"\"    \"To finish off the programming section, we’re going to give y… #>  7 \"h3\"  \"27.1.1 Prerequisites\"                                         #>  8 \"\"    \"This package focuses on base R so doesn’t have any real prer… #>  9 \"h2\"  \"27.2 Selecting multiple elements with [\"                      #> 10 \"\"    \"[ is used to extract sub-components from vectors and data fr… #> # ℹ 26 more rows  # use `frame_by_tags` to get a dataframe where the # headings associated with each text chunk are easily accessible file |>   ragnar_read_document(frame_by_tags = c(\"h1\", \"h2\", \"h3\")) #> # A tibble: 18 × 4 #>    h1                         h2                            h3    text  #>    <chr>                      <chr>                         <chr> <chr> #>  1 NA                         NA                            NA    \"Pro… #>  2 NA                         Table of contents             NA    \"27.… #>  3 27 A field guide to base R 27.1 Introduction             NA    \"To … #>  4 27 A field guide to base R 27.1 Introduction             27.1… \"Thi… #>  5 27 A field guide to base R 27.2 Selecting multiple elem… NA    \"[ i… #>  6 27 A field guide to base R 27.2 Selecting multiple elem… 27.2… \"The… #>  7 27 A field guide to base R 27.2 Selecting multiple elem… 27.2… \"The… #>  8 27 A field guide to base R 27.2 Selecting multiple elem… 27.2… \"Sev… #>  9 27 A field guide to base R 27.2 Selecting multiple elem… 27.2… \"Cre… #> 10 27 A field guide to base R 27.3 Selecting a single elem… NA    \"[, … #> 11 27 A field guide to base R 27.3 Selecting a single elem… 27.3… \"[[ … #> 12 27 A field guide to base R 27.3 Selecting a single elem… 27.3… \"The… #> 13 27 A field guide to base R 27.3 Selecting a single elem… 27.3… \"[[ … #> 14 27 A field guide to base R 27.3 Selecting a single elem… 27.3… \"Wha… #> 15 27 A field guide to base R 27.4 Apply family             NA    \"In … #> 16 27 A field guide to base R 27.5 for loops                NA    \"for… #> 17 27 A field guide to base R 27.6 Plots                    NA    \"Man… #> 18 27 A field guide to base R 27.7 Summary                  NA    \"In …  # use `split_by_tags` and `frame_by_tags` together to further break up `text`. file |>   ragnar_read_document(     split_by_tags = c(\"p\"),     frame_by_tags = c(\"h1\", \"h2\", \"h3\")   ) #> # A tibble: 117 × 5 #>    h1                         h2                      h3    tag   text  #>    <chr>                      <chr>                   <chr> <chr> <chr> #>  1 NA                         NA                      NA    \"\"    \"Pro… #>  2 NA                         Table of contents       NA    \"\"    \"27.… #>  3 27 A field guide to base R 27.1 Introduction       NA    \"p\"   \"To … #>  4 27 A field guide to base R 27.1 Introduction       NA    \"p\"   \"Thi… #>  5 27 A field guide to base R 27.1 Introduction       NA    \"p\"   \"Aft… #>  6 27 A field guide to base R 27.1 Introduction       NA    \"p\"   \"In … #>  7 27 A field guide to base R 27.1 Introduction       27.1… \"p\"   \"Thi… #>  8 27 A field guide to base R 27.1 Introduction       27.1… \"\"    \"lib… #>  9 27 A field guide to base R 27.2 Selecting multipl… NA    \"p\"   \"[ i… #> 10 27 A field guide to base R 27.2 Selecting multipl… 27.2… \"p\"   \"The… #> # ℹ 107 more rows  # Example workflow adding context to each chunk file |>   ragnar_read_document(frame_by_tags = c(\"h1\", \"h2\", \"h3\")) |>   glue::glue_data(r\"--(     ## Excerpt from the book \"R for Data Science (2e)\"     chapter: {h1}     section: {h2}     content: {text}      )--\") |>     # inspect     _[6:7] |> cat(sep = \"\\n~~~~~~~~~~~\\n\") #> ## Excerpt from the book \"R for Data Science (2e)\" #> chapter: 27 A field guide to base R #> section: 27.2 Selecting multiple elements with [ #> content: There are five main types of things that you can subset a vector with, i.e., that can be the i in x[i]: #>  #> A vector of positive integers. Subsetting with positive integers keeps the elements at those positions: #>  #> x <- c(\"one\", \"two\", \"three\", \"four\", \"five\") #> x[c(3, 2, 5)] #> #> [1] \"three\" \"two\"   \"five\" #>  #> By repeating a position, you can actually make a longer output than input, making the term “subsetting” a bit of a misnomer. #>  #> x[c(1, 1, 5, 5, 5, 2)] #> #> [1] \"one\"  \"one\"  \"five\" \"five\" \"five\" \"two\" #>  #> A vector of negative integers. Negative values drop the elements at the specified positions: #>  #> x[c(-1, -3, -5)] #> #> [1] \"two\"  \"four\" #>  #> A logical vector. Subsetting with a logical vector keeps all values corresponding to a TRUE value. This is most often useful in conjunction with the comparison functions. #>  #> x <- c(10, 3, NA, 5, 8, 1, NA) #>  #> # All non-missing values of x #> x[!is.na(x)] #> #> [1] 10  3  5  8  1 #>  #> # All even (or missing!) values of x #> x[x %% 2 == 0] #> #> [1] 10 NA  8 NA #>  #> Unlike filter(), NA indices will be included in the output as NAs. #>  #> A character vector. If you have a named vector, you can subset it with a character vector: #>  #> x <- c(abc = 1, def = 2, xyz = 5) #> x[c(\"xyz\", \"def\")] #> #> xyz def  #> #>   5   2 #>  #> As with subsetting with positive integers, you can use a character vector to duplicate individual entries. #>  #> Nothing. The final type of subsetting is nothing, x[], which returns the complete x. This is not useful for subsetting vectors, but as we’ll see shortly, it is useful when subsetting 2d structures like tibbles. #>  #> ~~~~~~~~~~~ #> ## Excerpt from the book \"R for Data Science (2e)\" #> chapter: 27 A field guide to base R #> section: 27.2 Selecting multiple elements with [ #> content: There are quite a few different ways1 that you can use [ with a data frame, but the most important way is to select rows and columns independently with df[rows, cols]. Here rows and cols are vectors as described above. For example, df[rows, ] and df[, cols] select just rows or just columns, using the empty subset to preserve the other dimension. #>  #> Here are a couple of examples: #>  #> df <- tibble( #>   x = 1:3,  #>   y = c(\"a\", \"e\", \"f\"),  #>   z = runif(3) #> ) #>  #> # Select first row and second column #> df[1, 2] #> #> # A tibble: 1 × 1 #> #>   y     #> #>   <chr> #> #> 1 a #>  #> # Select all rows and columns x and y #> df[, c(\"x\" , \"y\")] #> #> # A tibble: 3 × 2 #> #>       x y     #> #>   <int> <chr> #> #> 1     1 a     #> #> 2     2 e     #> #> 3     3 f #>  #> # Select rows where `x` is greater than 1 and all columns #> df[df$x > 1, ] #> #> # A tibble: 2 × 3 #> #>       x y         z #> #>   <int> <chr> <dbl> #> #> 1     2 e     0.834 #> #> 2     3 f     0.601 #>  #> We’ll come back to $ shortly, but you should be able to guess what df$x does from the context: it extracts the x variable from df. We need to use it here because [ doesn’t use tidy evaluation, so you need to be explicit about the source of the x variable. #>  #> There’s an important difference between tibbles and data frames when it comes to [. In this book, we’ve mainly used tibbles, which are data frames, but they tweak some behaviors to make your life a little easier. In most places, you can use “tibble” and “data frame” interchangeably, so when we want to draw particular attention to R’s built-in data frame, we’ll write data.frame. If df is a data.frame, then df[, cols] will return a vector if col selects a single column and a data frame if it selects more than one column. If df is a tibble, then [ will always return a tibble. #>  #> df1 <- data.frame(x = 1:3) #> df1[, \"x\"] #> #> [1] 1 2 3 #>  #> df2 <- tibble(x = 1:3) #> df2[, \"x\"] #> #> # A tibble: 3 × 1 #> #>       x #> #>   <int> #> #> 1     1 #> #> 2     2 #> #> 3     3 #>  #> One way to avoid this ambiguity with data.frames is to explicitly specify drop = FALSE: #>  #> df1[, \"x\" , drop = FALSE] #> #>   x #> #> 1 1 #> #> 2 2 #> #> 3 3 #>   # Advanced example of postprocessing the output of ragnar_read_document() # to wrap code blocks in backticks, markdown style library(dplyr, warn.conflicts = FALSE) library(stringr) library(rvest) library(xml2) file |>   ragnar_read_document(frame_by_tags = c(\"h1\", \"h2\", \"h3\"),                        split_by_tags = c(\"p\", \"pre\")) |>   mutate(     is_code = tag == \"pre\",     text = ifelse(is_code,                   str_c(\"```\", text, \"```\", sep = \"\\n\"),                   text)) |>   group_by(h1, h2, h3) |>   summarise(text = str_flatten(text, \"\\n\"), .groups = \"drop\") |>   glue::glue_data(r\"--(     # Excerpt from the book \"R for Data Science (2e)\"     chapter: {h1}     section: {h2}     content: {text}      )--\") |>     # inspect     _[9:10] |> cat(sep = \"\\n~~~~~~~~~~~\\n\") #> # Excerpt from the book \"R for Data Science (2e)\" #> chapter: 27 A field guide to base R #> section: 27.3 Selecting a single element with $ and [[ #> content: There are a couple of important differences between tibbles and base data.frames when it comes to $. Data frames match the prefix of any variable names (so-called partial matching) and don’t complain if a column doesn’t exist: #> ``` #> df <- data.frame(x1 = 1) #> df$x #> #> [1] 1 #> df$z #> #> NULL #> ``` #> Tibbles are more strict: they only ever match variable names exactly and they will generate a warning if the column you are trying to access doesn’t exist: #> ``` #> tb <- tibble(x1 = 1) #>  #> tb$x #> #> Warning: Unknown or uninitialised column: `x`. #> #> NULL #> tb$z #> #> Warning: Unknown or uninitialised column: `z`. #> #> NULL #> ``` #> For this reason we sometimes joke that tibbles are lazy and surly: they do less and complain more. #>  #> ~~~~~~~~~~~ #> # Excerpt from the book \"R for Data Science (2e)\" #> chapter: 27 A field guide to base R #> section: 27.3 Selecting a single element with $ and [[ #> content: [[ and $ are also really important for working with lists, and it’s important to understand how they differ from [. Let’s illustrate the differences with a list named l: #> ``` #> l <- list( #>   a = 1:3,  #>   b = \"a string\",  #>   c = pi,  #>   d = list(-1, -5) #> ) #> ``` #> [ extracts a sub-list. It doesn’t matter how many elements you extract, the result will always be a list. #> ``` #> str(l[1:2]) #> #> List of 2 #> #>  $ a: int [1:3] 1 2 3 #> #>  $ b: chr \"a string\" #>  #> str(l[1]) #> #> List of 1 #> #>  $ a: int [1:3] 1 2 3 #>  #> str(l[4]) #> #> List of 1 #> #>  $ d:List of 2 #> #>   ..$ : num -1 #> #>   ..$ : num -5 #> ``` #> Like with vectors, you can subset with a logical, integer, or character vector. #> [[ and $ extract a single component from a list. They remove a level of hierarchy from the list. #> ``` #> str(l[[1]]) #> #>  int [1:3] 1 2 3 #>  #> str(l[[4]]) #> #> List of 2 #> #>  $ : num -1 #> #>  $ : num -5 #>  #> str(l$a) #> #>  int [1:3] 1 2 3 #> ``` #> The difference between [ and [[ is particularly important for lists because [[ drills down into the list while [ returns a new, smaller list. To help you remember the difference, take a look at the unusual pepper shaker shown in Figure 27.1. If this pepper shaker is your list pepper, then, pepper[1] is a pepper shaker containing a single pepper packet. pepper[2] would look the same, but would contain the second packet. pepper[1:2] would be a pepper shaker containing two pepper packets. pepper[[1]] would extract the pepper packet itself. #> Figure 27.1: (Left) A pepper shaker that Hadley once found in his hotel room. (Middle) pepper[1]. (Right) pepper[[1]] #> This same principle applies when you use 1d [ with a data frame: df[\"x\"] returns a one-column data frame and df[[\"x\"]] returns a vector. #>   # Example of preprocessing the input to ragnar_read_document() # to wrap code in backticks, markdown style # same outcome as above, except via pre processing instead of post processing. file |>   read_html() |>   (\\(doc) {     # fence preformatted code with triple backticks     for (node in html_elements(doc, \"pre\")) {       xml_add_child(node, \"code\", \"```\\n\", .where = 0)       xml_add_child(node, \"code\", \"\\n```\")     }     # wrap inline code with single backticks     for (node in html_elements(doc, \"code\")) {       if (!\"pre\" %in% xml_name(xml_parents(node))) {         xml_text(node) <- str_c(\"`\", xml_text(node), \"`\")       }     }     doc   })() |>   ragnar_read_document(frame_by_tags = c(\"h1\", \"h2\", \"h3\")) |>   glue::glue_data(r\"--(     # Excerpt from the book \"R for Data Science (2e)\"     chapter: {h1}     section: {h2}     content: {text}      )--\") |> _[6] #> # Excerpt from the book \"R for Data Science (2e)\" #> chapter: 27 A field guide to base R #> section: 27.2 Selecting multiple elements with `[` #> content: There are five main types of things that you can subset a vector with, i.e., that can be the `i` in `x[i]`: #>  #> A vector of positive integers. Subsetting with positive integers keeps the elements at those positions: #>  #> ``` #> x <- c(\"one\", \"two\", \"three\", \"four\", \"five\") #> x[c(3, 2, 5)] #> #> [1] \"three\" \"two\"   \"five\" #> ``` #>  #> By repeating a position, you can actually make a longer output than input, making the term “subsetting” a bit of a misnomer. #>  #> ``` #> x[c(1, 1, 5, 5, 5, 2)] #> #> [1] \"one\"  \"one\"  \"five\" \"five\" \"five\" \"two\" #> ``` #>  #> A vector of negative integers. Negative values drop the elements at the specified positions: #>  #> ``` #> x[c(-1, -3, -5)] #> #> [1] \"two\"  \"four\" #> ``` #>  #> A logical vector. Subsetting with a logical vector keeps all values corresponding to a `TRUE` value. This is most often useful in conjunction with the comparison functions. #>  #> ``` #> x <- c(10, 3, NA, 5, 8, 1, NA) #>  #> # All non-missing values of x #> x[!is.na(x)] #> #> [1] 10  3  5  8  1 #>  #> # All even (or missing!) values of x #> x[x %% 2 == 0] #> #> [1] 10 NA  8 NA #> ``` #>  #> Unlike `filter()`, `NA` indices will be included in the output as `NA`s. #>  #> A character vector. If you have a named vector, you can subset it with a character vector: #>  #> ``` #> x <- c(abc = 1, def = 2, xyz = 5) #> x[c(\"xyz\", \"def\")] #> #> xyz def  #> #>   5   2 #> ``` #>  #> As with subsetting with positive integers, you can use a character vector to duplicate individual entries. #>  #> Nothing. The final type of subsetting is nothing, `x[]`, which returns the complete `x`. This is not useful for subsetting vectors, but as we’ll see shortly, it is useful when subsetting 2d structures like tibbles. #>"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_register_tool_retrieve.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a 'retrieve' tool with ellmer — ragnar_register_tool_retrieve","title":"Register a 'retrieve' tool with ellmer — ragnar_register_tool_retrieve","text":"Register 'retrieve' tool ellmer","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_register_tool_retrieve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a 'retrieve' tool with ellmer — ragnar_register_tool_retrieve","text":"","code":"ragnar_register_tool_retrieve(   chat,   store,   store_description = \"the knowledge store\",   ...,   name = NULL,   title = NULL )"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_register_tool_retrieve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a 'retrieve' tool with ellmer — ragnar_register_tool_retrieve","text":"chat ellmer:::Chat object. store string store location, RagnarStore object. store_description Optional string, used composing tool description. ... arguments passed ragnar_retrieve(). name, title Optional tool function name title. default, store@name store@title used present. tool name must valid R function name unique tools registered ellmer::Chat object. title used user-friendly display.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_register_tool_retrieve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Register a 'retrieve' tool with ellmer — ragnar_register_tool_retrieve","text":"chat, invisibly.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_register_tool_retrieve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Register a 'retrieve' tool with ellmer — ragnar_register_tool_retrieve","text":"","code":"if (FALSE) { # (file.exists(\"r4ds.ragnar.duckdb\") && Sys.getenv(\"OPENAI_API_KEY\") != \"\") system_prompt <- stringr::str_squish(\"   You are an expert assistant in R programming.   When responding, you first quote relevant material from books or documentation,   provide links to the sources, and then add your own context and interpretation. \") chat <- ellmer::chat_openai(system_prompt, model = \"gpt-4.1\")  store <- ragnar_store_connect(\"r4ds.ragnar.duckdb\") ragnar_register_tool_retrieve(chat, store) chat$chat(\"How can I subset a dataframe?\") }"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve chunks from a RagnarStore — ragnar_retrieve","title":"Retrieve chunks from a RagnarStore — ragnar_retrieve","text":"Combines vss bm25 search returns union chunks retrieved methods.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve chunks from a RagnarStore — ragnar_retrieve","text":"","code":"ragnar_retrieve(store, text, top_k = 3L, ..., deoverlap = TRUE)"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve chunks from a RagnarStore — ragnar_retrieve","text":"store RagnarStore object returned ragnar_store_connect() ragnar_store_create(). text Character. Query string match. top_k Integer. Number nearest entries find per method. ... Additional arguments passed lower-level retrieval functions. deoverlap Logical. TRUE (default) store@version == 2, overlapping chunks merged chunks_deoverlap().","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve chunks from a RagnarStore — ragnar_retrieve","text":"tibble retrieved chunks. row represents chunk always contains text column.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Retrieve chunks from a RagnarStore — ragnar_retrieve","text":"results re-ranked identifying unique values.","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve chunks from a RagnarStore — ragnar_retrieve","text":"","code":"if (FALSE) { # (rlang::is_installed(\"dbplyr\") && nzchar(Sys.getenv(\"OPENAI_API_KEY\")) && ragnar:::can_load_duckdb_extensions()) ## Build a small store with categories store <- ragnar_store_create(   embed = \\(x) ragnar::embed_openai(x, model = \"text-embedding-3-small\"),   extra_cols = data.frame(category = character()),   version = 1 # store text chunks directly )  ragnar_store_insert(   store,   data.frame(     category = c(rep(\"pets\", 3), rep(\"dessert\", 3)),     text     = c(\"playful puppy\", \"sleepy kitten\", \"curious hamster\",                  \"chocolate cake\", \"strawberry tart\", \"vanilla ice cream\")   ) ) ragnar_store_build_index(store)  # Top 3 chunks without filtering ragnar_retrieve(store, \"sweet\")  # Combine filter with similarity search ragnar_retrieve(store, \"sweet\", filter = category == \"dessert\") }"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_bm25.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieves chunks using the BM25 score — ragnar_retrieve_bm25","title":"Retrieves chunks using the BM25 score — ragnar_retrieve_bm25","text":"BM25 refers Okapi Best Matching 25. See doi:10.1561/1500000019  information.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_bm25.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieves chunks using the BM25 score — ragnar_retrieve_bm25","text":"","code":"ragnar_retrieve_bm25(   store,   text,   top_k = 3L,   ...,   k = 1.2,   b = 0.75,   conjunctive = FALSE,   filter )"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_bm25.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieves chunks using the BM25 score — ragnar_retrieve_bm25","text":"store RagnarStore object returned ragnar_store_connect() ragnar_store_create(). text String, text search . top_k Integer. Number nearest entries find per method. ... Additional arguments passed lower-level retrieval functions. k, b \\(k_1\\) \\(b\\) parameters Okapi BM25 retrieval method. conjunctive Whether make query conjunctive .e., terms query string must present order chunk retrieved. filter Optional. filter expression evaluated dplyr::filter().","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_bm25.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieves chunks using the BM25 score — ragnar_retrieve_bm25","text":"tibble ordered descending BM25 metric_value (higher relevant), metric_name column set \"bm25\".","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss.html","id":null,"dir":"Reference","previous_headings":"","what":"Vector Similarity Search Retrieval — ragnar_retrieve_vss","title":"Vector Similarity Search Retrieval — ragnar_retrieve_vss","text":"Computes similarity measure query document embeddings uses similarity rank retrieve document chunks.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vector Similarity Search Retrieval — ragnar_retrieve_vss","text":"","code":"ragnar_retrieve_vss(   store,   query,   top_k = 3L,   ...,   method = \"cosine_distance\",   query_vector = store@embed(query),   filter )"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vector Similarity Search Retrieval — ragnar_retrieve_vss","text":"store RagnarStore object returned ragnar_store_connect() ragnar_store_create(). query Character. query string embed use similarity search. top_k Integer. Maximum number document chunks retrieve. Defaults 3. ... Additional arguments passed methods. method Character. Similarity method use: \"cosine_distance\", \"euclidean_distance\", \"negative_inner_product\". Defaults \"cosine_distance\". query_vector Numeric vector. embedding query. Defaults store@embed(query). filter Optional. filter expression evaluated dplyr::filter().","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vector Similarity Search Retrieval — ragnar_retrieve_vss","text":"tibble top_k retrieved chunks, ordered metric_value.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Vector Similarity Search Retrieval — ragnar_retrieve_vss","text":"Supported methods: cosine_distance – cosine angle two vectors. euclidean_distance – L2 distance vectors. negative_inner_product – negative sum element-wise products. filter supplied, function first performs similarity search, applies filter outer SQL query. uses HNSW index possible falls back sequential scan large result sets filtered queries.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Vector Similarity Search Retrieval — ragnar_retrieve_vss","text":"results re-ranked identifying unique values.","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vector Similarity Search Retrieval — ragnar_retrieve_vss","text":"","code":"if (FALSE) { # (rlang::is_installed(\"dbplyr\") && nzchar(Sys.getenv(\"OPENAI_API_KEY\")) && ragnar:::can_load_duckdb_extensions()) ## Build a small store with categories store <- ragnar_store_create(   embed = \\(x) ragnar::embed_openai(x, model = \"text-embedding-3-small\"),   extra_cols = data.frame(category = character()),   version = 1 # store text chunks directly )  ragnar_store_insert(   store,   data.frame(     category = c(rep(\"pets\", 3), rep(\"dessert\", 3)),     text     = c(\"playful puppy\", \"sleepy kitten\", \"curious hamster\",                  \"chocolate cake\", \"strawberry tart\", \"vanilla ice cream\")   ) ) ragnar_store_build_index(store)  # Top 3 chunks without filtering ragnar_retrieve(store, \"sweet\")  # Combine filter with similarity search ragnar_retrieve(store, \"sweet\", filter = category == \"dessert\") }"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss_and_bm25.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve VSS and BM25 — ragnar_retrieve_vss_and_bm25","title":"Retrieve VSS and BM25 — ragnar_retrieve_vss_and_bm25","text":"Runs ragnar_retrieve_vss() ragnar_retrieve_bm25() get distinct documents.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss_and_bm25.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve VSS and BM25 — ragnar_retrieve_vss_and_bm25","text":"","code":"ragnar_retrieve_vss_and_bm25(store, text, top_k = 3, ...)"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss_and_bm25.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve VSS and BM25 — ragnar_retrieve_vss_and_bm25","text":"store RagnarStore object returned ragnar_store_connect() ragnar_store_create(). text Character. Query string match. top_k Integer, number entries retrieve using per method. ... Forwarded ragnar_retrieve_vss()","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss_and_bm25.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve VSS and BM25 — ragnar_retrieve_vss_and_bm25","text":"tibble retrieved chunks. row represents chunk always contains text column.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss_and_bm25.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Retrieve VSS and BM25 — ragnar_retrieve_vss_and_bm25","text":"results re-ranked identifying unique values.","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_retrieve_vss_and_bm25.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve VSS and BM25 — ragnar_retrieve_vss_and_bm25","text":"","code":"if (FALSE) { # (rlang::is_installed(\"dbplyr\") && nzchar(Sys.getenv(\"OPENAI_API_KEY\")) && ragnar:::can_load_duckdb_extensions()) ## Build a small store with categories store <- ragnar_store_create(   embed = \\(x) ragnar::embed_openai(x, model = \"text-embedding-3-small\"),   extra_cols = data.frame(category = character()),   version = 1 # store text chunks directly )  ragnar_store_insert(   store,   data.frame(     category = c(rep(\"pets\", 3), rep(\"dessert\", 3)),     text     = c(\"playful puppy\", \"sleepy kitten\", \"curious hamster\",                  \"chocolate cake\", \"strawberry tart\", \"vanilla ice cream\")   ) ) ragnar_store_build_index(store)  # Top 3 chunks without filtering ragnar_retrieve(store, \"sweet\")  # Combine filter with similarity search ragnar_retrieve(store, \"sweet\", filter = category == \"dessert\") }"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_atlas.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize a store using Embedding Atlas — ragnar_store_atlas","title":"Visualize a store using Embedding Atlas — ragnar_store_atlas","text":"Visualize store using Embedding Atlas","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_atlas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize a store using Embedding Atlas — ragnar_store_atlas","text":"","code":"ragnar_store_atlas(   store,   ...,   host = \"localhost\",   port = 3030,   launch.browser = interactive() )"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_atlas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize a store using Embedding Atlas — ragnar_store_atlas","text":"store RagnarStore object inspect. ... Passed shiny::runApp(). host Host run Embedding Atlas server . port Port run Embedding Atlas server . launch.browser Whether launch browser automatically.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_atlas.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Visualize a store using Embedding Atlas — ragnar_store_atlas","text":"function requires embedding-atlas Python package. Make sure installed reticulate Python environment. also uses arrow transfer data DuckDB store Python.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_atlas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize a store using Embedding Atlas — ragnar_store_atlas","text":"","code":"# \\dontrun{ # Connect or create a store store <- ragnar_store_connect(':memory:') #> Error in ragnar_store_connect(\":memory:\"): Store must be created with ragnar_store_create() # Launch the Embedding Atlas app ragnar_store_atlas(store) #> Error in ragnar_store_atlas(store): error in evaluating the argument 'conn' in selecting a method for function 'dbSendQuery': object 'store' not found # }"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_build_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a Ragnar Store index — ragnar_store_build_index","title":"Build a Ragnar Store index — ragnar_store_build_index","text":"search index must built calling ragnar_retrieve(). additional entries added store ragnar_store_insert(), ragnar_store_build_index() must called rebuild index.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_build_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a Ragnar Store index — ragnar_store_build_index","text":"","code":"ragnar_store_build_index(store, type = c(\"vss\", \"fts\"))"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_build_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a Ragnar Store index — ragnar_store_build_index","text":"store RagnarStore object type retrieval search type build index .","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_build_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a Ragnar Store index — ragnar_store_build_index","text":"store, invisibly.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_create.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and connect to a vector store — ragnar_store_create","title":"Create and connect to a vector store — ragnar_store_create","text":"Create connect vector store","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_create.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and connect to a vector store — ragnar_store_create","text":"","code":"ragnar_store_create(   location = \":memory:\",   embed = embed_ollama(),   ...,   embedding_size = ncol(embed(\"foo\")),   overwrite = FALSE,   extra_cols = NULL,   name = NULL,   title = NULL,   version = 2 )  ragnar_store_connect(location, ..., read_only = TRUE)"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_create.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and connect to a vector store — ragnar_store_create","text":"location filepath, :memory:. Location can also database name specified md:dbname, case database created MotherDuck connection established. embed function called character vector returns matrix embeddings. Note function serialized deserialized new R sessions, reference objects global parent environments. Make sure namespace function calls ::. additional R objects must available function, can optionally supply carrier::crate() packaged data. can also NULL stores need embed texts, example, using FTS algorithms ragnar_retrieve_bm25(). ... unused; must empty. embedding_size integer overwrite logical, location already exists extra_cols zero row data frame used specify additional columns added store. columns can used adding additional context retrieving. See examples information. vctrs::vec_cast() used consistently perform type checks casts inserting ragnar_store_insert(). name unique name store. Must match ^[-zA-Z0-9_-]+$ regex. Used ragnar_register_tool_retrieve() registering tools. title title store, used ragnar_register_tool_retrieve() store registered ellmer::Chat object. version integer. version store create. See details. read_only logical, whether returned connection can used modify store.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_create.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create and connect to a vector store — ragnar_store_create","text":"RagnarStore object","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_create.html","id":"store-versions","dir":"Reference","previous_headings":"","what":"Store versions","title":"Create and connect to a vector store — ragnar_store_create","text":"Version 2 – documents chunk ranges (default) version = 2, ragnar stores document records start end positions chunks. provides strong support overlapping chunk ranges de-overlapping retrieval, generally allows retrieving arbitrary ranges source documents, support modifying chunks directly insertion. Chunks can augmented via context field additional fields passed extra_cols. easiest way prepare chunks version = 2 read_as_markdown() markdown_chunk(). Version 1 – flat chunks version = 1, ragnar keeps chunks single table. lets easily modify chunk text insertion. However, dynamic rechunking (de-overlapping) extracting arbitrary ranges source documents supported, since original full documents longer available. Chunks can augmented modifying chunk text directly (e.g., glue()). Additionally, intend call ragnar_store_update(), responsibility provide rlang::hash(original_full_document) chunk. easiest way prepare chunks version = 1 ragnar_read() ragnar_chunk().","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_create.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create and connect to a vector store — ragnar_store_create","text":"","code":"# A store with a dummy embedding store <- ragnar_store_create(   embed = \\(x) matrix(stats::runif(10), nrow = length(x), ncol = 10),   version = 1 ) ragnar_store_insert(store, data.frame(text = \"hello\"))  # A store with a schema. When inserting into this store, users need to # provide an `area` column. store <- ragnar_store_create(   embed = \\(x) matrix(stats::runif(10), nrow = length(x), ncol = 10),   extra_cols = data.frame(area = character()),   version = 1 ) ragnar_store_insert(store, data.frame(text = \"hello\", area = \"rag\"))  # If you already have a data.frame with chunks that will be inserted into # the store, you can quickly create a suitable store with `vec_ptype()`: chunks <- data.frame(text = letters, area = \"rag\") store <- ragnar_store_create(   embed = \\(x) matrix(stats::runif(10), nrow = length(x), ncol = 10),   extra_cols = vctrs::vec_ptype(chunks),   version = 1 ) ragnar_store_insert(store, chunks)  # version = 2 (the default) has support for deoverlapping store <- ragnar_store_create(   # if embed = NULL, then only bm25 search is used (not vss)   embed = NULL ) doc <- MarkdownDocument(   paste0(letters, collapse = \"\"),   origin = \"/some/where\" ) chunks <- markdown_chunk(doc, target_size = 3, target_overlap = 2 / 3) chunks$context <- substring(chunks$text, 1, 1) chunks #> # @document@origin: /some/where #> # A tibble:         24 × 4 #>    start   end context text  #>    <int> <int> <chr>   <chr> #>  1     1     3 a       abc   #>  2     2     4 b       bcd   #>  3     3     5 c       cde   #>  4     4     6 d       def   #>  5     5     7 e       efg   #>  6     6     8 f       fgh   #>  7     7     9 g       ghi   #>  8     8    10 h       hij   #>  9     9    11 i       ijk   #> 10    10    12 j       jkl   #> # ℹ 14 more rows ragnar_store_insert(store, chunks) ragnar_store_build_index(store)  ragnar_retrieve(store, \"abc bcd xyz\", deoverlap = FALSE) #> # A tibble: 3 × 8 #>   origin      doc_id chunk_id start   end  bm25 context text  #>   <chr>        <int>    <int> <int> <int> <dbl> <chr>   <chr> #> 1 /some/where      1        1     1     3  1.22 a       abc   #> 2 /some/where      1        2     2     4  1.22 b       bcd   #> 3 /some/where      1       24    24    26  1.22 x       xyz   ragnar_retrieve(store, \"abc bcd xyz\", deoverlap = TRUE) #> # A tibble: 2 × 8 #>   origin      doc_id chunk_id  start   end bm25      context text  #>   <chr>        <int> <list>    <int> <int> <list>    <chr>   <chr> #> 1 /some/where      1 <int [2]>     1     4 <dbl [2]> a       abcd  #> 2 /some/where      1 <int [1]>    24    26 <dbl [1]> x       xyz"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_ingest.html","id":null,"dir":"Reference","previous_headings":"","what":"Concurrently ingest documents into a Ragnar store — ragnar_store_ingest","title":"Concurrently ingest documents into a Ragnar store — ragnar_store_ingest","text":"ragnar_store_ingest() distributes document preparation work multiple processes using mirai. worker calls prepare single path returns resulting chunks (warnings) main process, writes store.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_ingest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Concurrently ingest documents into a Ragnar store — ragnar_store_ingest","text":"","code":"ragnar_store_ingest(   store,   paths,   prepare = function(path) markdown_chunk(read_as_markdown(path)),   n_workers = NULL,   progress = TRUE )"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_ingest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Concurrently ingest documents into a Ragnar store — ragnar_store_ingest","text":"store RagnarStore. Currently version 2 stores supported. paths Character vector file paths URLs ingest. prepare Function converts single path MarkdownDocumentChunks object. called argument path return prepared chunks (without embedding column). n_workers Number worker processes use. Defaults smaller length(paths) parallel::detectCores() (minimum 1). progress Logical; TRUE, show CLI progress bar.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_ingest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Concurrently ingest documents into a Ragnar store — ragnar_store_ingest","text":"store, invisibly.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_insert.html","id":null,"dir":"Reference","previous_headings":"","what":"Inserts or updates chunks in a RagnarStore — ragnar_store_insert","title":"Inserts or updates chunks in a RagnarStore — ragnar_store_insert","text":"Inserts updates chunks RagnarStore","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_insert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inserts or updates chunks in a RagnarStore — ragnar_store_insert","text":"","code":"ragnar_store_insert(store, chunks)  ragnar_store_update(store, chunks)"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_insert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inserts or updates chunks in a RagnarStore — ragnar_store_insert","text":"store RagnarStore object chunks Content insert update. precise input structure depends store@version. See Details.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_insert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inserts or updates chunks in a RagnarStore — ragnar_store_insert","text":"store, invisibly.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_insert.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inserts or updates chunks in a RagnarStore — ragnar_store_insert","text":"Store Version 2 chunks must MarkdownDocumentChunks object. Store Version 1 chunks must data frame containing origin, hash, text columns. first filter chunks origin hash already store. origin store, different hash, replace chunks new chunks. Otherwise, regular insert performed. can help avoid needing compute embeddings chunks already store.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_inspect.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch the Ragnar Store Inspector — ragnar_store_inspect","title":"Launch the Ragnar Store Inspector — ragnar_store_inspect","text":"Launches Shiny app interactively browsing Ragnar store, previewing document chunks, testing search behavior.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_inspect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch the Ragnar Store Inspector — ragnar_store_inspect","text":"","code":"ragnar_store_inspect(store, ...)"},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_inspect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launch the Ragnar Store Inspector — ragnar_store_inspect","text":"store RagnarStore object inspect. ... Passed shiny::runApp().","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_inspect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Launch the Ragnar Store Inspector — ragnar_store_inspect","text":"NULL (invisibly).","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/ragnar_store_inspect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Launch the Ragnar Store Inspector — ragnar_store_inspect","text":"Store Inspector Shiny app exploring RagnarStore. Use quickly see ingested preview search results different queries. Type query search bar choose BM25 VSS. list documents left updates, clicking row shows text metadata right. can drag divider resize document list preview area. preview area shows chunk content. can view rendered Markdown switch “Raw Text” see stored text (long lines wrapped). Metadata shown text YAML format, including extra fields stored chunk.","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/read_as_markdown.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert files to Markdown — read_as_markdown","title":"Convert files to Markdown — read_as_markdown","text":"Convert files Markdown","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/read_as_markdown.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert files to Markdown — read_as_markdown","text":"","code":"read_as_markdown(   path,   ...,   origin = path,   html_extract_selectors = c(\"main\"),   html_zap_selectors = c(\"nav\") )"},{"path":"https://ragnar.tidyverse.org/dev/reference/read_as_markdown.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert files to Markdown — read_as_markdown","text":"path [string] filepath URL. Accepts wide variety file types, including plain text (markdown), PDF, PowerPoint, Word, Excel, images (EXIF metadata OCR), audio (EXIF metadata speech transcription), HTML, text-based formats (CSV, JSON, XML), ZIP files (iterates contents), YouTube URLs, EPUBs. ... Passed MarkItDown.convert(). origin value use @origin property returned MarkdownDocument. html_extract_selectors Character vector CSS selectors. match selector found document, matched node's contents converted. Unmatched extract selectors effect. html_zap_selectors Character vector CSS selectors. Elements matching selectors excluded (\"zapped\") HTML document conversion markdown. useful removing navigation bars, sidebars, headers, footers, unwanted elements. default, navigation elements (nav) excluded.","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/read_as_markdown.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert files to Markdown — read_as_markdown","text":"MarkdownDocument object, single string Markdown @origin property.","code":""},{"path":[]},{"path":"https://ragnar.tidyverse.org/dev/reference/read_as_markdown.html","id":"converting-html","dir":"Reference","previous_headings":"","what":"Converting HTML","title":"Convert files to Markdown — read_as_markdown","text":"converting HTML, might want omit certain elements, like sidebars, headers, footers, etc. can pass CSS selector strings either extract nodes exclude nodes conversion. easiest way make selectors use SelectorGadget: https://rvest.tidyverse.org/articles/selectorgadget.html can also right-click page select \"Inspect Element\" browser better understand HTML page's structure. comprehensive advanced usage CSS selectors, consult https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors---css-property https://facelessuser.github.io/soupsieve/selectors/","code":""},{"path":"https://ragnar.tidyverse.org/dev/reference/read_as_markdown.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert files to Markdown — read_as_markdown","text":"","code":"# \\dontrun{ # Convert HTML md <- read_as_markdown(\"https://r4ds.hadley.nz/base-R.html\") md #> <ragnar::MarkdownDocument> chr \"# 27  A field guide to base R – R for Data Science (2e)\\n\\n# 27  A field guide to base R\\n\\n## 27.1 Introductio\"| __truncated__ #>  @ origin: chr \"https://r4ds.hadley.nz/base-R.html\"  cat_head <- \\(md, n = 10) writeLines(head(strsplit(md, \"\\n\")[[1L]], n)) cat_head(md) #> # 27  A field guide to base R – R for Data Science (2e) #>  #> # 27  A field guide to base R #>  #> ## 27.1 Introduction #>  #> To finish off the programming section, we’re going to give you a quick tour of the most important base R functions that we don’t otherwise discuss in the book. These tools are particularly useful as you do more programming and will help you read code you’ll encounter in the wild. #>  #> This is a good place to remind you that the tidyverse is not the only way to solve data science problems. We teach the tidyverse in this book because tidyverse packages share a common design philosophy, increasing the consistency across functions, and making each new function or package a little easier to learn and use. It’s not possible to use the tidyverse without using base R, so we’ve actually already taught you a **lot** of base R functions: from `[library()](https://rdrr.io/r/base/library.html)` to load packages, to `[sum()](https://rdrr.io/r/base/sum.html)` and `[mean()](https://rdrr.io/r/base/mean.html)` for numeric summaries, to the factor, date, and POSIXct data types, and of course all the basic operators like `+`, `-`, `/`, `*`, `|`, `&`, and `!`. What we haven’t focused on so far is base R workflows, so we will highlight a few of those in this chapter. #>   ## Using selector strings  # By default, this output includes the sidebar and other navigational elements url <- \"https://duckdb.org/code_of_conduct\" read_as_markdown(url) |> cat_head(15) #> # Code of Conduct – DuckDB #>  #> Search Shortcut cmd + k | ctrl + k #>  #> # Code of Conduct #>  #> **All creatures are welcome**: We aim to create a safe space for all community members, regardless of their age, race, gender, sexual orientation, physical appearance or disability, choice of text editor, or any other qualities by which living beings can be discriminated. #>  #> **Be excellent to each other**: We do not tolerate verbal or physical harassment, violence or intimidation. #>  #> We do not tolerate life forms who refuse to share this openness and respect towards others: Creatures that are not excellent to others are not welcome. #>  #> We continuously strive to make our community a better place for everyone – in the best tradition of hackers we \"build, test, improve, reiterate\". In this ongoing adventure, we rely on the support, courage, and creativity of all members of the DuckDB community. #>  #> If you are made uncomfortable in your role as DuckDB community member, please let us know: You can reach us at [[email protected]](/cdn-cgi/l/email-protection#abdadecac8c0ebcfdec8c0cfc985c4d9cc). All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident.  # To extract just the main content, use a selector read_as_markdown(url, html_extract_selectors = \"#main_content_wrap\") |>   cat_head() #> # Code of Conduct – DuckDB #>  #> # Code of Conduct #>  #> **All creatures are welcome**: We aim to create a safe space for all community members, regardless of their age, race, gender, sexual orientation, physical appearance or disability, choice of text editor, or any other qualities by which living beings can be discriminated. #>  #> **Be excellent to each other**: We do not tolerate verbal or physical harassment, violence or intimidation. #>  #> We do not tolerate life forms who refuse to share this openness and respect towards others: Creatures that are not excellent to others are not welcome. #>   # Alternative approach: zap unwanted nodes read_as_markdown(   url,   html_zap_selectors = c(     \"header\",          # name     \".sidenavigation\", # class     \".searchoverlay\",  # class     \"#sidebar\"         # ID   ) ) |> cat_head() #> # Code of Conduct – DuckDB #>  #> # Code of Conduct #>  #> **All creatures are welcome**: We aim to create a safe space for all community members, regardless of their age, race, gender, sexual orientation, physical appearance or disability, choice of text editor, or any other qualities by which living beings can be discriminated. #>  #> **Be excellent to each other**: We do not tolerate verbal or physical harassment, violence or intimidation. #>  #> We do not tolerate life forms who refuse to share this openness and respect towards others: Creatures that are not excellent to others are not welcome. #>   # Quarto example read_as_markdown(   \"https://quarto.org/docs/computations/python.html\",   html_extract_selectors = \"main\",   html_zap_selectors = c(     \"#quarto-sidebar\",     \"#quarto-margin-sidebar\",     \"header\",     \"footer\",     \"nav\"   ) ) |> cat_head() #> # Using Python – Quarto #>  #> ## Overview #>  #> Quarto supports executable Python code blocks within markdown. This allows you to create fully reproducible documents and reports—the Python code required to produce your output is part of the document itself, and is automatically re-run whenever the document is rendered. #>  #> If you have Python and the `jupyter` package installed then you have all you need to render documents that contain embedded Python code (if you don’t, we’ll cover this in the [installation](#installation) section below). Next, we’ll cover the basics of creating and rendering documents with Python code blocks. #>  #> ### Code Blocks #>   ## Convert PDF pdf <- file.path(R.home(\"doc\"), \"NEWS.pdf\") read_as_markdown(pdf) |> cat_head(15) #> NEWS for R version 4.5.1 (2025-06-13) #>  #> NEWS #>  #> R News #>  #> CHANGES IN R 4.5.1 #>  #> NEW FEATURES: #>  #> (cid:136) The internal method of unzip() now follows unzip 6.00 in how it handles extracted #>  #> (cid:28)le paths which contain \"../\". With thanks to Ivan Krylov. #>  #> INSTALLATION: ## Alternative: # pdftools::pdf_text(pdf) |> cat_head()  # Convert images to markdown descriptions using OpenAI jpg <- file.path(R.home(\"doc\"), \"html\", \"logo.jpg\") if (Sys.getenv(\"OPENAI_API_KEY\") != \"\") {   # if (xfun::is_macos()) system(\"brew install ffmpeg\")   reticulate::py_require(\"openai\")   llm_client <- reticulate::import(\"openai\")$OpenAI()   read_as_markdown(jpg, llm_client = llm_client, llm_model = \"gpt-4.1-mini\") |>     writeLines()   # # Description:   # The image displays the logo of the R programming language. It features a   # large, stylized capital letter \"R\" in blue, positioned prominently in the   # center. Surrounding the \"R\" is a gray oval shape that is open on the right   # side, creating a dynamic and modern appearance. The R logo is commonly   # associated with statistical computing, data analysis, and graphical   # representation in various scientific and professional fields. }  # Alternative approach to image conversion: if (   Sys.getenv(\"OPENAI_API_KEY\") != \"\" &&     rlang::is_installed(\"ellmer\") &&     rlang::is_installed(\"magick\") ) {   chat <- ellmer::chat_openai(echo = TRUE)   chat$chat(\"Describe this image\", ellmer::content_image_file(jpg)) } # }"},{"path":"https://ragnar.tidyverse.org/dev/news/index.html","id":"ragnar-development-version","dir":"Changelog","previous_headings":"","what":"ragnar (development version)","title":"ragnar (development version)","text":"New embed_azure_openai() helper generating embeddings Azure AI Foundry (#144). New ragnar_store_atlas() application visualizing embeddings (#124). New ragnar_store_ingest() concurrently preparing inserting documents store parallel workers via mirai (#133). New function mcp_serve_store() supports letting local MCP client like Codex CLI Claude Code search RagnarStore (#123). default tool name prefix registered ragnar_register_tool_retrive() changed rag_retrieve_from_{store@name} search_{store@name}. Store Inspector updated keyboard shortcuts, draggable divider, improved preview linkification metadata display, visual tweaks general bug fixes (#120). Correct BM25 result ordering sort descending score (#122). embed_ollama() default model now embeddinggemma (#121). ragnar_find_links() now works better HTML files local filesystem. new default value children_only=FALSE return links page. See #115 details. read_as_markdown() gains origin argument control @origin recorded returned documents. RagnarStore print method now shows store location (#116) Errors messages executing embed_openai() now surfaced user (#112).","code":""},{"path":"https://ragnar.tidyverse.org/dev/news/index.html","id":"ragnar-021","dir":"Changelog","previous_headings":"","what":"ragnar 0.2.1","title":"ragnar 0.2.1","text":"CRAN release: 2025-08-19 ragnar_register_tool_retrieve() now registers tool return previously returned chunks, enabling LLM perform deeper searches ragnar store repeated tool calls (#106). Updates ellmer v0.3.0 duckdb v1.3.1 (#99) Improved docs error message ragnar_store_insert() (@mattwarkentin, #88) ragnar_find_links() can now parse sitemap.xml files. also gains validate argument, allowing sending HEAD request link filtering broken links (#83). ragnar_inspector() now renders urls clickable links chunk markdown viewer, even url formal markdown link (#82). running examples tests now check ragnar can load DuckDB extensions. fixes issues environments DuckDB pre-built binaries extensions compatible installed DuckDB version (#94). Added embed_lm_studio use LMStudio embedding provider (#100). Fixed bug causing ragnar_retrieve() fail documents inserted without origin (#102). now suppress “Couldn’t find ffmpeg avconv” warning importing markitdown using read_as_markdown(). warning relevant users audio transcription (#103). Added embed_google_gemini use Google Gemini API embedding provider (#105).","code":""},{"path":"https://ragnar.tidyverse.org/dev/news/index.html","id":"ragnar-020","dir":"Changelog","previous_headings":"","what":"ragnar 0.2.0","title":"ragnar 0.2.0","text":"CRAN release: 2025-07-12 ragnar_store_create() gains new argument: version, default 2. Store version 2 adds support chunk deoverlapping retrieval automatic chunk augmentation headings. support features, internal schema ingestion requirements different. See markdown_chunk() new S7 classes MarkdownDocument MarkdownDocumentChunks. Backwards compatibility maintained version = 1. (#58, #39, #36) ragnar_store_create() now supports Date POSIXct classes supplied extra_cols. ragnar_store_create() now supports remote MotherDuck Databases specified md:<dbname> location argument. (#50) ragnar_retrieve() friends gain filter argument, adding support efficiently filtering retrieval results. ragnar_retrieve_bm25() gains arguments b, k, conjunctive (#56). ragnar_retrieve_vss() gains argument query_vector, supporting workflows preprocess query string embedding. ragnar_retrieve_vss() set valid method choices updated narrower set ensure HNSW index scan used. Passing tbl(store) ragnar_retrieve() deprecated. New chunker markdown_chunk() support chunk heading context generation, semantic boundary selection, overlapping chunks, document segmentation, . (#56) New function embed_google_vertex() (@dfalbel, #49) New function embed_databricks() (@atheriel, #45) New function ragnar_chunks_view() quickly previewing chunks (#42) ragnar_register_tool_retrieve() gains optional name title arguments allow descriptive tool registration. values can also set ragnar_store_create() (#43). ragnar_read() read_as_markdown() now accept paths begin ~ (@topepo, #46, #48). Changes read_as_markdown() HTML conversion (#40, #51): New arguments html_extract_selectors html_zap_selectors provide flexible way exclude html page elements included converted markdown. code blocks now include language, available. Fixed handling nested code fences markdown output.","code":""},{"path":"https://ragnar.tidyverse.org/dev/news/index.html","id":"ragnar-010","dir":"Changelog","previous_headings":"","what":"ragnar 0.1.0","title":"ragnar 0.1.0","text":"CRAN release: 2025-05-30 Initial CRAN submission.","code":""}]
